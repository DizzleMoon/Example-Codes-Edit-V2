{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Iterable, Tuple, Callable\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import urllib.request\n",
    "import requests\n",
    "import curl\n",
    "import pycurl\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "# from IPython import qt\n",
    "from matplotlib.pyplot import figure\n",
    "from py.xml import raw\n",
    "from requests.api import get\n",
    "from matplotlib import pyplot as plt\n",
    "# from scratch.working_with_data import rescale\n",
    "# from scratch.multiple_regression import least_squares_fit, predict\n",
    "# from scratch.gradient_descent import gradient_step\n",
    "\n",
    "# from stats import mean, median, de_mean, standard_deviation, correlation\n",
    "# from gradient_descent import minimize_stochastic, maximize_stochastic, maximize_batch\n",
    "# from vector import dot, vector_add\n",
    "# from normal import normal_cdf\n",
    "# from matrix import make_matrix, get_column, shape, matrix_multiply\n",
    "# from logistic_regression import *\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from functools import partial, reduce\n",
    "\n",
    "from scipy.optimize import fmin_tnc\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from typing import Tuple\n",
    "# from gradient_descent import maximize_stochastic, maximize_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionOVR(object):\n",
    "    def __init__(self, eta=0.1, n_iter=50):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        self.w = []\n",
    "        m = X.shape[0]\n",
    "\n",
    "        for i in np.unique(y):\n",
    "            y_copy = np.where(y == i, 1, 0)\n",
    "            w = np.ones(X.shape[1])\n",
    "\n",
    "            for _ in range(self.n_iter):\n",
    "                output = X.dot(w)\n",
    "                errors = y_copy - self._sigmoid(output)\n",
    "                w += self.eta / m * errors.dot(X)\n",
    "            self.w.append((w, i))\n",
    "        return self\n",
    "    \n",
    "    def predict2(self, X):\n",
    "        output = np.insert(X, 0, 1, axis=1).dot(self.w)\n",
    "        return (np.floor(self._sigmoid(output) + .5)).astype(int)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [self._predict_one(i) for i in np.insert(X, 0, 1, axis=1)]\n",
    "    \n",
    "    def _predict_one(self, x):\n",
    "        return max((x.dot(w), c) for w, c in self.w)[1]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return sum(self.predict(X) == y) / len(y)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(iris.data, iris.target, test_size=.1)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi = LogisticRegressionOVR(n_iter=1000).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629629629629629\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(logi.score(X_train, y_train))\n",
    "print(logi.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5  , 0.5  , 0.5  , 0.731, 0.731, 0.881, 0.731, 0.731, 0.5  ,\n",
       "       0.881, 0.881, 0.731, 0.881, 0.5  , 0.5  , 0.731, 0.5  , 0.881,\n",
       "       0.5  , 0.5  , 0.731, 0.731, 0.731, 0.5  , 0.881, 0.731, 0.881,\n",
       "       0.5  , 0.881, 0.881, 0.881, 0.731, 0.5  , 0.731, 0.881, 0.881,\n",
       "       0.731, 0.731, 0.5  , 0.881, 0.731, 0.5  , 0.731, 0.5  , 0.881,\n",
       "       0.731, 0.881, 0.881, 0.5  , 0.881, 0.881, 0.881, 0.731, 0.881,\n",
       "       0.881, 0.731, 0.5  , 0.731, 0.5  , 0.5  , 0.5  , 0.731, 0.731,\n",
       "       0.881, 0.5  , 0.5  , 0.881, 0.731, 0.881, 0.881, 0.5  , 0.731,\n",
       "       0.731, 0.5  , 0.731, 0.5  , 0.881, 0.5  , 0.5  , 0.5  , 0.731,\n",
       "       0.731, 0.5  , 0.731, 0.731, 0.881, 0.5  , 0.731, 0.731, 0.731,\n",
       "       0.881, 0.731, 0.5  , 0.5  , 0.5  , 0.5  , 0.881, 0.731, 0.731,\n",
       "       0.881, 0.881, 0.731, 0.731, 0.881, 0.881, 0.881, 0.731, 0.5  ,\n",
       "       0.731, 0.731, 0.731, 0.731, 0.731, 0.881, 0.881, 0.881, 0.5  ,\n",
       "       0.5  , 0.5  , 0.5  , 0.731, 0.881, 0.881, 0.881, 0.881, 0.881,\n",
       "       0.5  , 0.881, 0.731, 0.731, 0.881, 0.5  , 0.5  , 0.881, 0.881])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi._sigmoid(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1,\n",
       "       1, 0, 2, 1, 2, 0, 2, 2, 2, 1, 0, 1, 2, 2, 1, 1, 0, 2, 1, 0, 1, 0,\n",
       "       2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 2, 1, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0,\n",
       "       2, 1, 2, 2, 0, 1, 1, 0, 1, 0, 2, 0, 0, 0, 1, 1, 0, 1, 1, 2, 0, 1,\n",
       "       1, 1, 2, 1, 0, 0, 0, 0, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 0, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 2, 1, 1, 2, 0,\n",
       "       0, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
