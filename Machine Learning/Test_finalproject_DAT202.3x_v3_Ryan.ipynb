{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34956/4064691247.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpygal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygal'"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Iterable, Tuple, Callable\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import pygal\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import urllib.request\n",
    "import requests\n",
    "import curl\n",
    "import pycurl\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "# from IPython import qt\n",
    "from matplotlib.pyplot import figure\n",
    "from py.xml import raw\n",
    "from requests.api import get\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from functools import partial, reduce\n",
    "from scipy.optimize import fmin_tnc\n",
    "import itertools\n",
    "import random\n",
    "import tqdm\n",
    "from typing import*\n",
    "from collections import*\n",
    "from scipy import*\n",
    "from sklearn.metrics import*\n",
    "from numpy import *\n",
    "import mnist\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn import*\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionCustom(object):\n",
    "    def __init__(self, alpha=0.1, iteration=5000):\n",
    "        # Learning Rate\n",
    "        self.alpha = alpha\n",
    "        self.iteration = iteration\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        # Use normal equation\n",
    "        self.w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "        m = X.shape[0]\n",
    "\n",
    "        for _ in range(self.iteration):\n",
    "            output = X.dot(self.w)\n",
    "            errors = y - self.sigmoid(output)\n",
    "            self.w += self.alpha / m * errors.dot(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = np.insert(X, 0, 1, axis=1).dot(self.w)\n",
    "        return (np.floor(self.sigmoid(output) + .5)).astype(int)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return sum(self.predict(X) == y) / len(y)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# Create input dataset\n",
    "df_loans_full = pd.read_csv('MergedLabeled.csv', header = None, skiprows=1)\n",
    "# df_loans_full = pd.read_csv('MergedLabeled.csv')\n",
    "df_loans_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string data column to numeric data column: Term\n",
    "for i in range(len(df_loans_full[7])):\n",
    "    label = df_loans_full.iloc[i,7]\n",
    "    label = label[:2].split(\" \")[-1]    \n",
    "    df_loans_full.iloc[i,7] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "# col = [6,7,8,9,15,16,17,18,19,20,21,22,23,24,25,26,27]\n",
    "# col = [6,7,8,9,15,16,17,18,19]\n",
    "# col = [6,7,8]\n",
    "col = [6,7]\n",
    "df_loans = df_loans_full.iloc[:,col]\n",
    "loans_df = df_loans\n",
    "df_loans\n",
    "# loans_df.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dataset\n",
    "# Binary vector. Rate of bad loans\n",
    "df_isbad = df_loans_full.iloc[:,28]\n",
    "df_isbad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loans dataset\n",
    "loans = df_loans.to_numpy()\n",
    "pred = df_isbad.to_numpy()\n",
    "pred = np.asarray(pred,dtype('float'))\n",
    "loans = np.asarray(loans,dtype('float'))\n",
    "# Reshape dataset\n",
    "loans = loans.reshape(len(df_loans),len(col))\n",
    "pred = pred.reshape(len(df_loans),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Logistic Regression\n",
    "\n",
    "# Split Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(loans, pred, test_size=0.3)\n",
    "\n",
    "# Apply Logistic Regression\n",
    "logi = LogisticRegressionCustom().fit(X_train, y_train.ravel())\n",
    "# Accuracy Rate\n",
    "print(logi.score(X_train, y_train.ravel()))\n",
    "# Prediction\n",
    "pred_X_train = logi.predict(X_test) \n",
    "\n",
    "\n",
    "# Create prediction vector.\n",
    "# Create list of indexes \n",
    "test_val = 0\n",
    "test_val_index = []\n",
    "for i in range(len(pred_X_train)):\n",
    "#     print(pred_X_train[i])\n",
    "    if pred_X_train[i] == y_test[i]:\n",
    "        test_val += 1\n",
    "        test_val_index.append(i)\n",
    "# List of Indexes\n",
    "# print(test_val_index)\n",
    "# Number of predicted values against orginal values\n",
    "print(test_val)\n",
    "# Length of list of split binary vector\n",
    "len(pred_X_train)\n",
    "\n",
    "# List of Predicted Values (0 & 1)\n",
    "# predicted = []\n",
    "predicted = y_test\n",
    "for i in range(len(pred_X_train)):\n",
    "    if i < test_val:\n",
    "        if i == test_val_index[i]:\n",
    "            predicted[i] = pred_X_train[i]\n",
    "    else:\n",
    "        predicted[i] = int(y_test[i].tolist()[0])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn Logisitc Regression model\n",
    "\n",
    "# Sklearn Logistic Regression function\n",
    "clf = LogisticRegression().fit(X_train, y_train.ravel())\n",
    "# Accuracy\n",
    "print(clf.score(X_train,y_train))\n",
    "# Predicted vector\n",
    "clf_pred = clf.predict(X_test)\n",
    "# clf_pred[clf_pred == 1]\n",
    "\n",
    "# Create prediction vector.\n",
    "# Create list of indexes \n",
    "test_val_reg = 0\n",
    "test_val_index_reg = []\n",
    "for i in range(len(clf_pred)):\n",
    "#     print(pred_X_train[i])\n",
    "    if clf_pred[i] == y_test[i]:\n",
    "        test_val_reg += 1\n",
    "        test_val_index_reg.append(i)\n",
    "# List of Indexes\n",
    "# print(test_val_index_reg)\n",
    "# Number of predicted values against orginal values\n",
    "print(test_val_reg)\n",
    "# Length of list of split binary vecto\n",
    "# len(clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of Predicted values (0 or 1)\n",
    "# predicted = []\n",
    "predicted_reg = y_test\n",
    "for i in range(len(pred_X_train)):\n",
    "    if i < test_val_reg:\n",
    "        if i == test_val_index_reg[i]:\n",
    "            predicted_reg[i] = pred_X_train[i]\n",
    "    else:\n",
    "        predicted_reg[i] = int(y_test[i].tolist()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe to compare original, sklearn and predicted values (0 or 1)\n",
    "df_pred_concat = pd.DataFrame([pred[0:len(predicted)].tolist(),predicted,predicted_reg])\n",
    "df_pred = df_pred_concat.T\n",
    "df_pred.columns=['Original', 'SkLearn', 'Custom']\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
