{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "from stats import mean, de_mean, standard_deviation, correlation\n",
    "from gradient_descent import minimize_stochastic\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.104e+03, 3.000e+00, 3.999e+05],\n",
       "       [1.600e+03, 3.000e+00, 3.299e+05],\n",
       "       [2.400e+03, 3.000e+00, 3.690e+05],\n",
       "       [1.416e+03, 2.000e+00, 2.320e+05],\n",
       "       [3.000e+03, 4.000e+00, 5.399e+05]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"ex1data2.txt\",dtype=np.float64,delimiter=\",\")\n",
    "data[:5,::] #dataset loaded demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break datasets into X and Y.\n",
    "X_0 = np.array(data[::,0:2])\n",
    "Y = data[::,-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 2.104e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.600e+03, 3.000e+00],\n",
       "       [1.000e+00, 2.400e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.416e+03, 2.000e+00],\n",
       "       [1.000e+00, 3.000e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.985e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.534e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.427e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.380e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.494e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.940e+03, 4.000e+00],\n",
       "       [1.000e+00, 2.000e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.890e+03, 3.000e+00],\n",
       "       [1.000e+00, 4.478e+03, 5.000e+00],\n",
       "       [1.000e+00, 1.268e+03, 3.000e+00],\n",
       "       [1.000e+00, 2.300e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.320e+03, 2.000e+00],\n",
       "       [1.000e+00, 1.236e+03, 3.000e+00],\n",
       "       [1.000e+00, 2.609e+03, 4.000e+00],\n",
       "       [1.000e+00, 3.031e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.767e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.888e+03, 2.000e+00],\n",
       "       [1.000e+00, 1.604e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.962e+03, 4.000e+00],\n",
       "       [1.000e+00, 3.890e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.100e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.458e+03, 3.000e+00],\n",
       "       [1.000e+00, 2.526e+03, 3.000e+00],\n",
       "       [1.000e+00, 2.200e+03, 3.000e+00],\n",
       "       [1.000e+00, 2.637e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.839e+03, 2.000e+00],\n",
       "       [1.000e+00, 1.000e+03, 1.000e+00],\n",
       "       [1.000e+00, 2.040e+03, 4.000e+00],\n",
       "       [1.000e+00, 3.137e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.811e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.437e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.239e+03, 3.000e+00],\n",
       "       [1.000e+00, 2.132e+03, 4.000e+00],\n",
       "       [1.000e+00, 4.215e+03, 4.000e+00],\n",
       "       [1.000e+00, 2.162e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.664e+03, 2.000e+00],\n",
       "       [1.000e+00, 2.238e+03, 3.000e+00],\n",
       "       [1.000e+00, 2.567e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.200e+03, 3.000e+00],\n",
       "       [1.000e+00, 8.520e+02, 2.000e+00],\n",
       "       [1.000e+00, 1.852e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.203e+03, 3.000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup bias array\n",
    "X_ones = np.ones(len(X_0))\n",
    "# Concentate arrays\n",
    "# X = [X_ones,X_0]\n",
    "X1 = np.vstack((X_ones.T,X_0.T))\n",
    "# X1 = [[X_ones],[X_0]]\n",
    "X1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta = np.linalg.pinv(X1.dot(X1.T)).dot(X1).dot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "# Mean\n",
    "mean_size = np.mean(X1[1])\n",
    "mean_bedroom = np.mean(X1[2])\n",
    "# Standard Deviation\n",
    "std_size = np.std(X1[1])\n",
    "std_bedroom = np.std(X1[2])\n",
    "# Scaling\n",
    "X1[1] = (X1[1] - mean_size)/std_size\n",
    "X1[2] = (X1[2] - mean_bedroom)/std_bedroom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to find cost\n",
    "def cost_function(X, y, theta):\n",
    "    \"\"\"\n",
    "    cost_function(X, y, theta) computes the cost of using theta as the\n",
    "    parameter for linear regression to fit the data points in X and y\n",
    "    \"\"\"\n",
    "    ## number of training examples\n",
    "    m = len(y) \n",
    "    \n",
    "    ## Calculate the cost with the given parameters\n",
    "    J = np.sum((X.dot(theta)-y)**2)/2/m\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,y,theta,alpha,num_iters):\n",
    "    \"\"\"\n",
    "    Take in numpy array X, y and theta and update theta by taking   num_iters gradient steps\n",
    "    with learning rate of alpha\n",
    "    \n",
    "    return theta and the list of the cost of theta during each  iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    m=len(y)\n",
    "    J_history=[]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        predictions = X.dot(theta)\n",
    "#         error = np.dot(X.transpose(),(predictions -y))\n",
    "        error = X.T.dot(predictions-y)\n",
    "        descent=alpha * 1/m * error\n",
    "        theta = theta - descent\n",
    "        J_history.append(cost_function(X, y, theta))\n",
    "    \n",
    "    return theta,J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "iterations = 100\n",
    "t,J = gradientDescent(X1.T,Y,Theta,alpha,iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of house with 1650 sq ft and 3 bedroom is  [293081.47270562]\n"
     ]
    }
   ],
   "source": [
    "# predict the price of a house with 1650 square feet and 3 bedrooms\n",
    "# add bias unit 1.0\n",
    "X_predict = np.array([1.0,1650.0,3]) \n",
    "#feature scaling the data first\n",
    "X_predict[1] = (X_predict[1] - mean_size)/ (std_size) \n",
    "X_predict[2] = (X_predict[2]- mean_bedroom)/ (std_bedroom)\n",
    "hypothesis = X_predict.dot(t)\n",
    "print(\"Cost of house with 1650 sq ft and 3 bedroom is \",hypothesis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
