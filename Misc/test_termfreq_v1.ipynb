{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "np.set_printoptions(precision=7)\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "from sympy import * \n",
    "from collections import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences\n",
    "# Sentence_1 = 'We went to the pizza place and you ate no pizza at all.'\n",
    "# Sentence_2 = 'I ate pizza with you yesterday at home.'\n",
    "# Sentence_3 = 'Thereâ€™s no place like home'\n",
    "\n",
    "# Sentence_1 = 'The sky is blue'\n",
    "# Sentence_2 = 'The sky is not blue'\n",
    "\n",
    "Sentence_1 = 'The sun is the largest celestial body in the solar system'\n",
    "Sentence_2 = 'The solar system consists of the sun and eight revolving planets'\n",
    "Sentence_3 = 'Ra was the Egyptian Sun God'\n",
    "Sentence_4 = 'The Pyramids were the pinnacle of Egyptian architecture'\n",
    "Sentence_5 = 'The quick brown fox jumps over the lazy dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 2, 'The': 1, 'sun': 1, 'is': 1, 'largest': 1, 'celestial': 1, 'body': 1, 'in': 1, 'solar': 1, 'system': 1})\n",
      "Counter({'Ra': 1, 'was': 1, 'the': 1, 'Egyptian': 1, 'Sun': 1, 'God': 1})\n",
      "Counter({'Ra': 1, 'was': 1, 'the': 1, 'Egyptian': 1, 'Sun': 1, 'God': 1})\n",
      "Counter({'The': 1, 'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'the': 1, 'lazy': 1, 'dog': 1})\n",
      "\n",
      "\n",
      "[1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Count\n",
    "Sen_1 = Sentence_1.split()\n",
    "# print(Sen_1)\n",
    "Sen_2 = Sentence_2.split()\n",
    "# print(Sen_2)\n",
    "Sen_3 = Sentence_3.split()\n",
    "# print(Sen_3)\n",
    "Sen_4 = Sentence_4.split()\n",
    "# print(Sen_3)\n",
    "Sen_5 = Sentence_5.split()\n",
    "# print(Sen_3)\n",
    "\n",
    "# Dictionary\n",
    "Sent_1 = Counter(Sen_1)\n",
    "print(Sent_1)\n",
    "Sent_2 = Counter(Sen_2)\n",
    "# print(Sent_2)\n",
    "Sent_3 = Counter(Sen_3)\n",
    "print(Sent_3)\n",
    "Sent_4 = Counter(Sen_4)\n",
    "print(Sent_3)\n",
    "Sent_5 = Counter(Sen_5)\n",
    "print(Sent_5)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "count = []\n",
    "for i in Sen_1:\n",
    "    cnt = Sen_1.count(i)\n",
    "    count.append(cnt)\n",
    "    \n",
    "print(count)\n",
    " \n",
    "# print(Sent_1['pizza'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Egyptian',\n",
       " 'God',\n",
       " 'Pyramids',\n",
       " 'Ra',\n",
       " 'Sun',\n",
       " 'The',\n",
       " 'and',\n",
       " 'architecture',\n",
       " 'body',\n",
       " 'brown',\n",
       " 'celestial',\n",
       " 'consists',\n",
       " 'dog',\n",
       " 'eight',\n",
       " 'fox',\n",
       " 'in',\n",
       " 'is',\n",
       " 'jumps',\n",
       " 'largest',\n",
       " 'lazy',\n",
       " 'of',\n",
       " 'over',\n",
       " 'pinnacle',\n",
       " 'planets',\n",
       " 'quick',\n",
       " 'revolving',\n",
       " 'solar',\n",
       " 'sun',\n",
       " 'system',\n",
       " 'the',\n",
       " 'was',\n",
       " 'were'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordset = set(Sen_1 ).union(set(Sen_2)).union(set(Sen_3)).union(set(Sen_4)).union(set(Sen_5))\n",
    "wordset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictinonary for each document\n",
    "doc_1  = dict.fromkeys(wordset,0)\n",
    "doc_2  = dict.fromkeys(wordset,0)\n",
    "doc_3  = dict.fromkeys(wordset,0)\n",
    "doc_4  = dict.fromkeys(wordset,0)\n",
    "doc_5  = dict.fromkeys(wordset,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the words\n",
    "for word in Sen_1:\n",
    "    doc_1[word] += 1\n",
    "    \n",
    "for word in Sen_2:\n",
    "    doc_2[word] += 1\n",
    "    \n",
    "for word in Sen_3:\n",
    "    doc_3[word] += 1\n",
    "    \n",
    "for word in Sen_4:\n",
    "    doc_4[word] += 1\n",
    "    \n",
    "for word in Sen_5:\n",
    "    doc_5[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   The  of  brown  were  revolving  jumps  was  body  eight  sun  ...  Ra  \\\n",
      "0    1   0      0     0          0      0    0     1      0    1  ...   0   \n",
      "1    1   1      0     0          1      0    0     0      1    1  ...   0   \n",
      "2    0   0      0     0          0      0    1     0      0    0  ...   1   \n",
      "3    1   1      0     1          0      0    0     0      0    0  ...   0   \n",
      "4    1   0      1     0          0      1    0     0      0    0  ...   0   \n",
      "\n",
      "   architecture  solar  the  and  over  Egyptian  lazy  fox  is  \n",
      "0             0      1    2    0     0         0     0    0   1  \n",
      "1             0      1    1    1     0         0     0    0   0  \n",
      "2             0      0    1    0     0         1     0    0   0  \n",
      "3             1      0    1    0     0         1     0    0   0  \n",
      "4             0      0    1    0     1         0     1    1   0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "docs = pd.DataFrame([doc_1,doc_2,doc_3,doc_4,doc_5])\n",
    "print(docs)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# # Column names\n",
    "# for col in docs.columns:\n",
    "#     print(col)\n",
    "    \n",
    "# print('\\n')\n",
    "\n",
    "\n",
    "# # Row names\n",
    "# for row in range(len(docs)):\n",
    "#     print(row)\n",
    "#     print(docs.iloc[row])\n",
    "    \n",
    "# print('\\n')\n",
    "\n",
    "# # Num of occurences for column title 'the'\n",
    "# print(docs['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer()\n",
      "  (0, 26)\t0.2720650001570024\n",
      "  (0, 24)\t0.2720650001570024\n",
      "  (0, 11)\t0.33721755509592094\n",
      "  (0, 2)\t0.33721755509592094\n",
      "  (0, 4)\t0.33721755509592094\n",
      "  (0, 14)\t0.33721755509592094\n",
      "  (0, 12)\t0.33721755509592094\n",
      "  (0, 25)\t0.2258385267674438\n",
      "  (0, 27)\t0.4820579154855759\n",
      "  (1, 19)\t0.3469067733890991\n",
      "  (1, 23)\t0.3469067733890991\n",
      "  (1, 8)\t0.3469067733890991\n",
      "  (1, 0)\t0.3469067733890991\n",
      "  (1, 16)\t0.27988220046765916\n",
      "  (1, 5)\t0.3469067733890991\n",
      "  (1, 26)\t0.27988220046765916\n",
      "  (1, 24)\t0.27988220046765916\n",
      "  (1, 25)\t0.23232750918188863\n",
      "  (1, 27)\t0.3306058725208975\n",
      "  (2, 10)\t0.48076438934193244\n",
      "  (2, 7)\t0.3878776821823183\n",
      "  (2, 28)\t0.48076438934193244\n",
      "  (2, 22)\t0.48076438934193244\n",
      "  (2, 25)\t0.321973514636116\n",
      "  (2, 27)\t0.22908680747650192\n",
      "  (3, 1)\t0.40128418717786946\n",
      "  (3, 18)\t0.40128418717786946\n",
      "  (3, 29)\t0.40128418717786946\n",
      "  (3, 20)\t0.40128418717786946\n",
      "  (3, 7)\t0.3237535555244\n",
      "  (3, 16)\t0.3237535555244\n",
      "  (3, 27)\t0.38242813057436686\n",
      "  (4, 6)\t0.3555988681343606\n",
      "  (4, 15)\t0.3555988681343606\n",
      "  (4, 17)\t0.3555988681343606\n",
      "  (4, 13)\t0.3555988681343606\n",
      "  (4, 9)\t0.3555988681343606\n",
      "  (4, 3)\t0.3555988681343606\n",
      "  (4, 21)\t0.3555988681343606\n",
      "  (4, 27)\t0.33888953195832316\n",
      "(5, 30)\n",
      "[[1.        0.364132  0.1831471 0.1843525 0.1633644]\n",
      " [0.364132  1.        0.1505407 0.2170458 0.1120389]\n",
      " [0.1831471 0.1505407 1.        0.213186  0.0776351]\n",
      " [0.1843525 0.2170458 0.213186  1.        0.1296009]\n",
      " [0.1633644 0.1120389 0.0776351 0.1296009 1.       ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Corpus = [Sentence_1,Sentence_2,Sentence_3,Sentence_4,Sentence_5]\n",
    "# print(Corpus)\n",
    "\n",
    "# Initialize an instance of tf-idf Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "print(tfidf_vectorizer)\n",
    "\n",
    "# Generate the tf-idf vectors for the corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(Corpus)\n",
    "print(tfidf_matrix)\n",
    "print(tfidf_matrix.shape)\n",
    "\n",
    "# compute and print the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
