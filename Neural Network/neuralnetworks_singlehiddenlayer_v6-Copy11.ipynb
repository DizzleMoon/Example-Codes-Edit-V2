{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "def cost(actual,predict):\n",
    "#   m = 4\n",
    "  m = actual.shape[0]\n",
    "  print('m_cost:', m)\n",
    "  cost__ = -np.sum(np.multiply(np.log(predict), actual) + np.multiply((1 - actual), np.log(1 - predict)))/m\n",
    "  return np.squeeze(cost__)\n",
    "\n",
    "def feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(w1 * x[0] + w2 * x[1] + w3 * x[2] + b1)\n",
    "    h2 = sigmoid(w4 * x[0] + w5 * x[1] + w6 * x[2] + b2)\n",
    "    o1 = sigmoid(w7 * h1 + w8 * h2 + b3)\n",
    "    return o1\n",
    "\n",
    "def feedforward2(W1,W2,w7,w8,b1,b2,b3,x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(np.dot(W1,x.T) + b1)\n",
    "    h2 = sigmoid(np.dot(W2,x.T) + b2)\n",
    "    o1 = sigmoid(w7 * h1 + w8 * h2 + b3)\n",
    "    return o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.seed(10)\n",
    "# X_xor=np.array([[0,0,1,1],[0,1,0,1]])\n",
    "# Y=np.array([0,1,1,0])\n",
    "# data_xor = X_xor.T\n",
    "# network.train(data_xor, Y)\n",
    "\n",
    "# Define dataset\n",
    "np.random.seed(5)\n",
    "# data = np.array([\n",
    "#   [-2, -1],  # Alice\n",
    "#   [25, 6],   # Bob\n",
    "#   [17, 4],   # Charlie\n",
    "#   [-15, -6], # Diana\n",
    "# ])\n",
    "# all_y_trues = np.array([\n",
    "#   1, # Alice\n",
    "#   0, # Bob\n",
    "#   0, # Charlie\n",
    "#   1, # Diana\n",
    "# ])\n",
    "# print(data.shape)\n",
    "\n",
    "# np.random.seed(15)\n",
    "X_xor=np.array([[0,0,1,1],[0,1,0,1],[1,0,1,0]])\n",
    "all_y_trues=np.array([0,1,1,0])\n",
    "data = X_xor.T\n",
    "data.shape\n",
    "\n",
    "# network.train(data_xor, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "w1 = np.random.normal()\n",
    "w10 = w1\n",
    "w2 = np.random.normal()\n",
    "w20 = w2\n",
    "w3 = np.random.normal()\n",
    "w30 = w3\n",
    "w4 = np.random.normal()\n",
    "w40 = w4\n",
    "w5 = np.random.normal()\n",
    "w50 = w5\n",
    "w6 = np.random.normal()\n",
    "w60 = w6\n",
    "w7 = np.random.normal()\n",
    "w70 = w7\n",
    "w8 = np.random.normal()\n",
    "w80 = w8\n",
    "\n",
    "\n",
    "# Biases\n",
    "b1 = np.random.normal()\n",
    "b10 = b1\n",
    "b2 = np.random.normal()\n",
    "b20 = b2\n",
    "b3 = np.random.normal()\n",
    "b30 = b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate_wg = 2.1\n",
    "learn_rate_bias = 1.2\n",
    "epochs = 1000 # number of times to loop through the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002250105738747975\n",
      "0.0002250105738747975\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "W1 = np.random.randn(1,3)\n",
    "W2 = np.random.randn(1,3)\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for x, y_true in zip(data, all_y_trues):\n",
    "        # --- Do a feedforward (we'll need these values later)\n",
    "#         sum_h1 = w1 * x[0] + w2 * x[1] + w3*x[2] + b1\n",
    "#         h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_h1 = np.squeeze(np.dot(W1,x.T) + b1)\n",
    "        h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_h2 = w4 * x[0] + w5 * x[1] + w6*x[2] + b2\n",
    "        h2 = sigmoid(sum_h2)\n",
    "\n",
    "        sum_h2 = np.squeeze(np.dot(W2,x.T) + b1)\n",
    "        h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_o1 = w7 * h1 + w8 * h2 + b3\n",
    "        o1 = sigmoid(sum_o1)\n",
    "        y_pred = o1\n",
    "        \n",
    "#         d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "        m = y_true + 1\n",
    "#             print('m:', m)\n",
    "        d_L_d_ypred = -((y_true - y_pred)/(y_pred*(1 - y_pred)))/m\n",
    "        \n",
    "        # Neuron o1\n",
    "        d_ypred_d_w7 = h1 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_w8 = h2 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
    "\n",
    "        d_ypred_d_h1 = w7 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_h2 = w8 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "        # Neuron h1\n",
    "        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_w3 = x[2] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
    "        neuron_h1 = np.dot(x.T,deriv_sigmoid(sum_h1))\n",
    "\n",
    "        # Neuron h2\n",
    "        d_h2_d_w4 = x[0] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_w5 = x[1] * deriv_sigmoid(sum_h2)\n",
    "        d_h1_d_w6 = x[2] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
    "        neuron_h2 = np.dot(x.T,deriv_sigmoid(sum_h2))\n",
    "\n",
    "        # --- Update weights and biases\n",
    "        # Neuron h1\n",
    "        w1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "        w2 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "        w3 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w3\n",
    "        b1 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "        for i in range(len(W1)):\n",
    "            W1[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1[i]\n",
    "\n",
    "        # Neuron h2\n",
    "        w4 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "        w5 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w5\n",
    "        w6 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h2 * d_h1_d_w6\n",
    "        b2 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "        for i in range(len(W2)):\n",
    "            W2[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2[i]\n",
    "\n",
    "        # Neuron o1\n",
    "        w7 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_w7\n",
    "        w8 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_w8\n",
    "        b3 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_b3\n",
    "\n",
    "        # --- Calculate total loss at the end of each epoch\n",
    "#         if epoch % 10 == 0:\n",
    "#             y_preds = np.apply_along_axis(feedforward(w1,w2,w3,w4,w5,w6,b1,b2,b3,x), 1, data)\n",
    "# #             loss = mse_loss(all_y_trues, y_preds)\n",
    "#             loss = cost(all_y_trues, y_preds)\n",
    "#             print(\"Epoch %d loss: %.5f\" % (epoch, loss))\n",
    "\n",
    "print(d_h1_d_w1)\n",
    "print(d_h1_d_w2)\n",
    "print(d_h1_d_w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make some predictions\n",
    "# emily = np.array([-7, -3]) # 128 pounds, 63 inches\n",
    "# frank = np.array([20, 2])  # 155 pounds, 68 inches\n",
    "# print(\"Emily: %.7f\" % feedforward(w1,w2,w3,w4,w5,w6,b1,b2,b3,emily)) # 0.951 - F\n",
    "# print(\"Frank: %.7f\" % feedforward(w1,w2,w3,w4,w5,w6,b1,b2,b3,frank)) # 0.039 - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00047783458447386845\n",
      "[0.36421434]\n",
      "0.001013514589474488\n",
      "[0.00101351]\n",
      "0.0004430496691254735\n",
      "[0.21966273]\n",
      "0.0006602626255782488\n",
      "[0.36516799]\n"
     ]
    }
   ],
   "source": [
    "# # Make some predictions\n",
    "test = np.array([1, 0, 1]) # 128 pounds, 63 inches\n",
    "print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "test = np.array([0, 0, 0])  # 155 pounds, 68 inches\n",
    "print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "test = np.array([0, 0, 1])  # 155 pounds, 68 inches\n",
    "print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "test = np.array([1, 1, 1])  # 155 pounds, 68 inches\n",
    "print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "# print(\"Emily: %.3f\" % network.feedforward(emily)) # 0.951 - F\n",
    "# print(\"Frank: %.3f\" % network.feedforward(frank)) # 0.039 - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
