{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "def cost(actual,predict):\n",
    "#   m = 4\n",
    "  m = actual.shape[0]\n",
    "  print('m_cost:', m)\n",
    "  cost__ = -np.sum(np.multiply(np.log(predict), actual) + np.multiply((1 - actual), np.log(1 - predict)))/m\n",
    "  return np.squeeze(cost__)\n",
    "\n",
    "def feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(w1 * x[0] + w2 * x[1] + w3 * x[2] + b1)\n",
    "    h2 = sigmoid(w4 * x[0] + w5 * x[1] + w6 * x[2] + b2)\n",
    "    o1 = sigmoid(w7 * h1 + w8 * h2 + b3)\n",
    "    return o1\n",
    "\n",
    "def feedforward2(W1,W2,w7,w8,b1,b2,b3,x, data):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    # x1\n",
    "    x = x.reshape(data.shape[1],1)\n",
    "    h1 = sigmoid(np.dot(W1,x) + b1)\n",
    "    h2 = sigmoid(np.dot(W2,x) + b2)\n",
    "    o1 = sigmoid(w7 * h1 + w8 * h2 + b3)\n",
    "    return np.squeeze(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_xor=np.array([[0,1,1,0]])\n",
    "# all_y_trues=np.array([0,1,1,0])\n",
    "# data = X_xor.T\n",
    "# data.shape[0]\n",
    "\n",
    "# X_xor=np.array([[0,0,1,1],[0,1,0,1]])\n",
    "# all_y_trues=np.array([0,1,1,0])\n",
    "# data = X_xor.T\n",
    "# data.shape[0]\n",
    "# seed_num = data.shape[0] * data.shape[1]\n",
    "\n",
    "\n",
    "# X_xor=np.array([[0,0,1,1],[0,1,0,1],[1,0,1,0],[1,0,0,1],[1,1,0,0]])\n",
    "# all_y_trues=np.array([0,1,1,0])\n",
    "# data = X_xor.T\n",
    "# data.shape[0]\n",
    "# seed_num = data.shape[0] * data.shape[1] \n",
    "\n",
    "# X_xor=np.array([[0,0,1,1],[0,1,0,1],[1,0,1,0]])\n",
    "# all_y_trues=np.array([0,1,1,0])\n",
    "# data = X_xor.T\n",
    "# data.shape[0]\n",
    "# seed_num = data.shape[0] * data.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "w7 = np.random.normal()\n",
    "w8 = np.random.normal()\n",
    "\n",
    "# Biases\n",
    "b1 = np.random.normal()\n",
    "b2 = np.random.normal()\n",
    "b3 = np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate_wg = 2.2\n",
    "learn_rate_bias = 2.2\n",
    "epochs = 1000 # number of times to loop through the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(X_xor) == 1:\n",
    "#     # W1 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "#     # W2 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "#     W1 = np.random.normal()\n",
    "#     W2 = np.random.normal()\n",
    "# else:\n",
    "#     W1 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "#     W2 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "    \n",
    "# for epoch in range(epochs):\n",
    "#     for x, y_true in zip(data, all_y_trues):\n",
    "#         # --- Do a feedforward (we'll need these values later)\n",
    "\n",
    "#         # x1\n",
    "#         x = x.reshape(data.shape[1],1)\n",
    "\n",
    "#         # H1\n",
    "# #         sum_h1_0 = w1 * x[0] + w2 * x[1] + w3*x[2] + b1\n",
    "# #         h1_0 = sigmoid(sum_h1_0)\n",
    "\n",
    "#         # H1 alternative\n",
    "# #         W1 = np.random.normal(size=(1,3))\n",
    "#         sum_h1 = np.dot(W1,x) + b1\n",
    "#         h1 = sigmoid(sum_h1)\n",
    "\n",
    "#         # H2\n",
    "# #         sum_h2_0 = w4 * x[0] + w5 * x[1] + w6*x[2] + b2\n",
    "# #         h2_0 = sigmoid(sum_h2_0)\n",
    "\n",
    "#         # H2 alternative\n",
    "# #         W2 = np.random.normal(size=(1,3))\n",
    "#         sum_h2 = np.dot(W2,x) + b2\n",
    "#         h2 = sigmoid(sum_h2)\n",
    "\n",
    "#         sum_o1 = w7 * h1 + w8 * h2 + b3\n",
    "#         o1 = sigmoid(sum_o1)\n",
    "#         y_pred = o1\n",
    "\n",
    "# #         d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "# #         m_true = y_true + 1\n",
    "# #         print('M:',m_true)\n",
    "# #         m = y_true + data.shape[0]\n",
    "#         m = 4\n",
    "# #             print('m:', m)\n",
    "#         d_L_d_ypred = ((y_pred - y_true)/(y_pred*(1 - y_pred)))/(m)\n",
    "\n",
    "#         # Neuron o1\n",
    "#         d_ypred_d_w7 = h1 * deriv_sigmoid(sum_o1)\n",
    "#         d_ypred_d_w8 = h2 * deriv_sigmoid(sum_o1)\n",
    "#         d_ypred_d_b3 = deriv_sigmoid(sum_o1)/m\n",
    "\n",
    "#         d_ypred_d_h1 = w7 * deriv_sigmoid(sum_o1)\n",
    "#         d_ypred_d_h2 = w8 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "#         # Neuron h1\n",
    "# #         d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "# #         d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "# #         d_h1_d_w3 = x[2] * deriv_sigmoid(sum_h1)\n",
    "#         d_h1_d_b1 = deriv_sigmoid(sum_h1)/m\n",
    "#         neuron_h1 = np.dot(x,deriv_sigmoid(sum_h1))\n",
    "\n",
    "#         # Neuron h2\n",
    "# #         d_h2_d_w4 = x[0] * deriv_sigmoid(sum_h2)\n",
    "# #         d_h2_d_w5 = x[1] * deriv_sigmoid(sum_h2)\n",
    "# #         d_h2_d_w6 = x[2] * deriv_sigmoid(sum_h2)\n",
    "#         d_h2_d_b2 = deriv_sigmoid(sum_h2)/m\n",
    "#         neuron_h2 = np.dot(x,deriv_sigmoid(sum_h2))\n",
    "\n",
    "# #         for k in range(len(W1)):\n",
    "# #             W1[k] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1[k]\n",
    "# #             W2[k] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2[k]\n",
    "\n",
    "\n",
    "#         # --- Update weights and biases\n",
    "#         # Neuron h1\n",
    "# #         w1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "# #         w2 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "# #         w3 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w3\n",
    "#         b1 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "# #         for i in range(len(neuron_h1)):\n",
    "# #         W1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1\n",
    "\n",
    "\n",
    "#         # Neuron h2\n",
    "# #         w4 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "# #         w5 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w5\n",
    "# #         w6 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w6\n",
    "#         b2 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "# #         for i in range(len(neuron_h2)):\n",
    "# #         W2 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2\n",
    "\n",
    "#         if len(neuron_h1) <= 1:\n",
    "#             W1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1\n",
    "#             W2 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2\n",
    "#         else:\n",
    "#             for i in range(len(neuron_h1)):\n",
    "#                 W1[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1[i]\n",
    "#                 W2[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2[i]\n",
    "\n",
    "\n",
    "#         # Neuron o1\n",
    "#         w7 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_w7\n",
    "#         w8 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_w8\n",
    "#         b3 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_b3\n",
    "\n",
    "# #        --- Calculate total loss at the end of each epoch\n",
    "# #         if epoch % 10 == 0:\n",
    "# #             y_preds = np.apply_along_axis(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,x), 1, data)\n",
    "# # #             y_preds = np.apply_along_axis(feedforward2(W1,W2,w7,w8,b1,b2,b3,x), 1, data)\n",
    "# # #             loss = mse_loss(all_y_trues, y_preds)\n",
    "# #             loss = cost(all_y_trues, y_preds)\n",
    "# #             print(\"Epoch %d loss: %.5f\" % (epoch, loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fit_2(data,all_y_trues,w7,w8,b1,b2,b3):\n",
    "\n",
    "    np.random.seed(8)\n",
    "    \n",
    "    learn_rate_wg = 2.2\n",
    "    learn_rate_bias = 2.2\n",
    "    epochs = 1000 # number of times to loop through the entire dataset\n",
    "\n",
    "    if len(X_xor) == 1:\n",
    "        # W1 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "        # W2 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "        W1 = np.random.normal()\n",
    "        W2 = np.random.normal()\n",
    "    else:\n",
    "        W1 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "        W2 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        h1_sum = []\n",
    "        h2_sum = []  \n",
    "        for x, y_true in zip(data, all_y_trues):\n",
    "            # --- Do a feedforward (we'll need these values later)\n",
    "\n",
    "            # x1\n",
    "            x = x.reshape(data.shape[1],1)\n",
    "\n",
    "            # H1\n",
    "    #         sum_h1_0 = w1 * x[0] + w2 * x[1] + w3*x[2] + b1\n",
    "    #         h1_0 = sigmoid(sum_h1_0)\n",
    "\n",
    "            # H1 alternative\n",
    "    #         W1 = np.random.normal(size=(1,3))\n",
    "            sum_h1 = np.dot(W1,x) + b1\n",
    "            h1 = sigmoid(sum_h1)\n",
    "            h1_sum.append(sum_h1)\n",
    "\n",
    "            # H2\n",
    "    #         sum_h2_0 = w4 * x[0] + w5 * x[1] + w6*x[2] + b2\n",
    "    #         h2_0 = sigmoid(sum_h2_0)\n",
    "\n",
    "            # H2 alternative\n",
    "    #         W2 = np.random.normal(size=(1,3))\n",
    "            sum_h2 = np.dot(W2,x) + b2\n",
    "            h2 = sigmoid(sum_h2)\n",
    "            h2_sum.append(sum_h2)\n",
    "\n",
    "            sum_o1 = w7 * h1 + w8 * h2 + b3\n",
    "            o1 = sigmoid(sum_o1)\n",
    "            y_pred = o1\n",
    "            \n",
    "            hidden_layer = [h1_sum,h2_sum]\n",
    "\n",
    "    #         d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "    #         m_true = y_true + 1\n",
    "    #         print('M:',m_true)\n",
    "    #         m = y_true + data.shape[0]\n",
    "            m = 4\n",
    "    #             print('m:', m)\n",
    "            d_L_d_ypred = ((y_pred - y_true)/(y_pred*(1 - y_pred)))/(m)\n",
    "\n",
    "            # Neuron o1\n",
    "            d_ypred_d_w7 = h1 * deriv_sigmoid(sum_o1)\n",
    "            d_ypred_d_w8 = h2 * deriv_sigmoid(sum_o1)\n",
    "            d_ypred_d_b3 = deriv_sigmoid(sum_o1)/m\n",
    "\n",
    "            d_ypred_d_h1 = w7 * deriv_sigmoid(sum_o1)\n",
    "            d_ypred_d_h2 = w8 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "            # Neuron h1\n",
    "    #         d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "    #         d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "    #         d_h1_d_w3 = x[2] * deriv_sigmoid(sum_h1)\n",
    "            d_h1_d_b1 = deriv_sigmoid(sum_h1)/m\n",
    "            neuron_h1 = np.dot(x,deriv_sigmoid(sum_h1))\n",
    "\n",
    "            # Neuron h2\n",
    "    #         d_h2_d_w4 = x[0] * deriv_sigmoid(sum_h2)\n",
    "    #         d_h2_d_w5 = x[1] * deriv_sigmoid(sum_h2)\n",
    "    #         d_h2_d_w6 = x[2] * deriv_sigmoid(sum_h2)\n",
    "            d_h2_d_b2 = deriv_sigmoid(sum_h2)/m\n",
    "            neuron_h2 = np.dot(x,deriv_sigmoid(sum_h2))\n",
    "\n",
    "    #         for k in range(len(W1)):\n",
    "    #             W1[k] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1[k]\n",
    "    #             W2[k] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2[k]\n",
    "\n",
    "\n",
    "            # --- Update weights and biases\n",
    "            # Neuron h1\n",
    "    #         w1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "    #         w2 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "    #         w3 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w3\n",
    "            b1 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "    #         for i in range(len(neuron_h1)):\n",
    "    #         W1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1\n",
    "\n",
    "\n",
    "            # Neuron h2\n",
    "    #         w4 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "    #         w5 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w5\n",
    "    #         w6 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w6\n",
    "            b2 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "    #         for i in range(len(neuron_h2)):\n",
    "    #         W2 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2\n",
    "\n",
    "            if len(neuron_h1) <= 1:\n",
    "                W1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1\n",
    "                W2 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2\n",
    "            else:\n",
    "                for i in range(len(neuron_h1)):\n",
    "                    W1[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1[i]\n",
    "                    W2[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2[i]\n",
    "\n",
    "\n",
    "            # Neuron o1\n",
    "            w7 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_w7\n",
    "            w8 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_w8\n",
    "            b3 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_b3\n",
    "\n",
    "    #        --- Calculate total loss at the end of each epoch\n",
    "    #         if epoch % 10 == 0:\n",
    "    #             y_preds = np.apply_along_axis(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,x), 1, data)\n",
    "    # #             y_preds = np.apply_along_axis(feedforward2(W1,W2,w7,w8,b1,b2,b3,x), 1, data)\n",
    "    # #             loss = mse_loss(all_y_trues, y_preds)\n",
    "    #             loss = cost(all_y_trues, y_preds)\n",
    "    #             print(\"Epoch %d loss: %.5f\" % (epoch, loss))\n",
    "    \n",
    "    return W1,W2,w7,w8,b1,b2,b3,hidden_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Make some predictions\n",
    "# if len(X_xor) == 1:\n",
    "#     test = np.array([0]) # 128 pounds, 63 inches\n",
    "#     # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "#     print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     test = np.array([1])  # 155 pounds, 68 inches\n",
    "#     # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "#     print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     test = np.array([1])  # 155 pounds, 68 inches\n",
    "#     # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "#     print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     test = np.array([0])  # 155 pounds, 68 inches\n",
    "#     # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "#     print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     # # print(\"Emily: %.3f\" % network.feedforward(emily)) # 0.951 - F\n",
    "#     # # print(\"Frank: %.3f\" % network.feedforward(frank)) # 0.039 - Mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_fit(data,all_y_trues,w7,w8,b1,b2,b3):\n",
    "#     learn_rate_wg = 2.2\n",
    "#     learn_rate_bias = 2.2\n",
    "#     epochs = 1000 # number of times to loop through the entire dataset\n",
    "    \n",
    "#     W1 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "#     W2 = np.squeeze(np.random.normal(size=(1,data.shape[1])))\n",
    "#     for epoch in range(epochs):\n",
    "#         for x, y_true in zip(data, all_y_trues):\n",
    "#             # --- Do a feedforward (we'll need these values later)\n",
    "\n",
    "#             # x1\n",
    "#             x = x.reshape(data.shape[1],1)\n",
    "\n",
    "#             # H1\n",
    "#     #         sum_h1_0 = w1 * x[0] + w2 * x[1] + w3*x[2] + b1\n",
    "#     #         h1_0 = sigmoid(sum_h1_0)\n",
    "\n",
    "#             # H1 alternative\n",
    "#     #         W1 = np.random.normal(size=(1,3))\n",
    "#             sum_h1 = np.dot(W1,x) + b1\n",
    "#             h1 = sigmoid(sum_h1)\n",
    "\n",
    "#             # H2\n",
    "#     #         sum_h2_0 = w4 * x[0] + w5 * x[1] + w6*x[2] + b2\n",
    "#     #         h2_0 = sigmoid(sum_h2_0)\n",
    "\n",
    "#             # H2 alternative\n",
    "#     #         W2 = np.random.normal(size=(1,3))\n",
    "#             sum_h2 = np.dot(W2,x) + b2\n",
    "#             h2 = sigmoid(sum_h2)\n",
    "\n",
    "#             sum_o1 = w7 * h1 + w8 * h2 + b3\n",
    "#             o1 = sigmoid(sum_o1)\n",
    "#             y_pred = o1\n",
    "\n",
    "#     #         d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "#             m_true = y_true + 1\n",
    "#     #         print('M:',m_true)\n",
    "#             m = y_true + data.shape[0]\n",
    "#     #             print('m:', m)\n",
    "#             d_L_d_ypred = ((y_pred - y_true)/(y_pred*(1 - y_pred)))/(m_true)\n",
    "\n",
    "#             # Neuron o1\n",
    "#             d_ypred_d_w7 = h1 * deriv_sigmoid(sum_o1)\n",
    "#             d_ypred_d_w8 = h2 * deriv_sigmoid(sum_o1)\n",
    "#             d_ypred_d_b3 = deriv_sigmoid(sum_o1)/m\n",
    "\n",
    "#             d_ypred_d_h1 = w7 * deriv_sigmoid(sum_o1)\n",
    "#             d_ypred_d_h2 = w8 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "#             # Neuron h1\n",
    "#     #         d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "#     #         d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "#     #         d_h1_d_w3 = x[2] * deriv_sigmoid(sum_h1)\n",
    "#             d_h1_d_b1 = deriv_sigmoid(sum_h1)/m\n",
    "#             neuron_h1 = np.dot(x,deriv_sigmoid(sum_h1))\n",
    "\n",
    "#             # Neuron h2\n",
    "#     #         d_h2_d_w4 = x[0] * deriv_sigmoid(sum_h2)\n",
    "#     #         d_h2_d_w5 = x[1] * deriv_sigmoid(sum_h2)\n",
    "#     #         d_h2_d_w6 = x[2] * deriv_sigmoid(sum_h2)\n",
    "#             d_h2_d_b2 = deriv_sigmoid(sum_h2)/m\n",
    "#             neuron_h2 = np.dot(x,deriv_sigmoid(sum_h2))\n",
    "\n",
    "#     #         for k in range(len(W1)):\n",
    "#     #             W1[k] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1[k]\n",
    "#     #             W2[k] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2[k]\n",
    "\n",
    "\n",
    "#             # --- Update weights and biases\n",
    "#             # Neuron h1\n",
    "#     #         w1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "#     #         w2 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "#     #         w3 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w3\n",
    "#             b1 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "#     #         for i in range(len(neuron_h1)):\n",
    "#     #             W1[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1[i]\n",
    "\n",
    "\n",
    "#             # Neuron h2\n",
    "#     #         w4 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "#     #         w5 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w5\n",
    "#     #         w6 -= learn_rate_wg* d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w6\n",
    "#             b2 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "#     #         for i in range(len(neuron_h2)):\n",
    "#     #             W2[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2[i]\n",
    "\n",
    "#             if len(neuron_h1) <= 1:\n",
    "#                 W1 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1\n",
    "#                 W2 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2\n",
    "#             else:\n",
    "#                 for i in range(len(neuron_h1)):\n",
    "#                     W1[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h1 * neuron_h1[i]\n",
    "#                     W2[i] -= learn_rate_wg * d_L_d_ypred * d_ypred_d_h2 * neuron_h2[i]\n",
    "\n",
    "\n",
    "#             # Neuron o1\n",
    "#             w7 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_w7\n",
    "#             w8 -= learn_rate_wg * d_L_d_ypred * d_ypred_d_w8\n",
    "#             b3 -= learn_rate_bias * d_L_d_ypred * d_ypred_d_b3\n",
    "            \n",
    "\n",
    "# #     #        --- Calculate total loss at the end of each epoch\n",
    "# #             if epoch % 10 == 0:\n",
    "# #                 y_preds = np.apply_along_axis(feedforward2(W1,W2,w7,w8,b1,b2,b3,x), 0, data)\n",
    "# #     #             y_preds = np.apply_along_axis(feedforward2(W1,W2,w7,w8,b1,b2,b3,x), 1, data)\n",
    "# #     #             loss = mse_loss(all_y_trues, y_preds)\n",
    "# #                 loss = cost(all_y_trues, y_preds)\n",
    "# #                 print(\"Epoch %d loss: %.5f\" % (epoch, loss))\n",
    "            \n",
    "#     return W1,W2,w7,w8,b1,b2,b3\n",
    "\n",
    "#     # print(d_h1_d_w1)\n",
    "#     # print(d_h1_d_w2)\n",
    "#     # print(d_h1_d_w3)\n",
    "#     # print(W2)\n",
    "#     # print(sum_h2_0)\n",
    "#     # print(sum_h2)\n",
    "\n",
    "#     # print(d_h1_d_w1)\n",
    "#     # print(d_h1_d_w2)\n",
    "#     # print(d_h1_d_w3)\n",
    "#     # print(neuron_h1)\n",
    "\n",
    "#     # print(d_h2_d_w4)\n",
    "#     # print(d_h2_d_w5)\n",
    "#     # print(d_h2_d_w6)\n",
    "#     # print(neuron_h2)\n",
    "\n",
    "#     # print(w1)\n",
    "#     # print(w2)\n",
    "#     # print(w3)\n",
    "#     # print(W1)\n",
    "\n",
    "#     # print(w4)\n",
    "#     # print(w5)\n",
    "#     # print(w6)\n",
    "#     # print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_xor=np.array([[0,1,1,0]])\n",
    "# all_y_trues=np.array([0,1,1,0])\n",
    "# data = X_xor.T\n",
    "# data.shape[0]\n",
    "# seed_num = 2\n",
    "\n",
    "X_xor=np.array([[0,0,1,1],[0,1,0,1]])\n",
    "all_y_trues=np.array([0,1,1,0])\n",
    "data = X_xor.T\n",
    "data.shape[0]\n",
    "seed_num = data.shape[0] * data.shape[1]\n",
    "\n",
    "\n",
    "# X_xor=np.array([[0,0,1,1],[0,1,0,1],[1,0,1,0],[1,0,0,1],[1,1,0,0]])\n",
    "# all_y_trues=np.array([0,1,1,0])\n",
    "# data = X_xor.T\n",
    "# data.shape[0]\n",
    "# seed_num = data.shape[0] * data.shape[1] \n",
    "\n",
    "# X_xor=np.array([[0,0,1,1],[0,1,0,1],[1,0,1,0]])\n",
    "# all_y_trues=np.array([0,1,1,0])\n",
    "# data = X_xor.T\n",
    "# data.shape[0]\n",
    "# seed_num = data.shape[0] * data.shape[1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hl1: [[  6.06105896   1.95414899]\n",
      " [  1.94876223  -2.14110404]\n",
      " [  1.25666986  -6.49486803]\n",
      " [ -6.33660162 -14.09112719]]\n",
      "data: [[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "data2: [[  6.06105896   1.95414899]\n",
      " [  1.94876223  -2.14110404]\n",
      " [  1.25666986  -6.49486803]\n",
      " [ -6.33660162 -14.09112719]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed_num)\n",
    "for _ in range(0,2):\n",
    "    W1,W2,w7,w8,b1,b2,b3,hidden_layer = train_fit_2(data,all_y_trues,w7,w8,b1,b2,b3)\n",
    "#     data = np.array(hidden_layer).reshape(4,2)\n",
    "#     W1,W2,w7,w8,b1,b2,b3,hidden_layer = train_fit_2(data,all_y_trues,w7,w8,b1,b2,b3)\n",
    "#     data = np.array(hidden_layer).reshape(4,2)\n",
    "#     data = hl1\n",
    "\n",
    "# # len(hidden_la)\n",
    "hl1 = np.array(hidden_layer).reshape(4,2)\n",
    "print('hl1:',hl1)\n",
    "\n",
    "data2 = np.squeeze(hl1)\n",
    "print('data:',data)\n",
    "print('data2:',data2)\n",
    "\n",
    "\n",
    "# for j in range(len(data2)):\n",
    "#     for k in range(len(data2[0])):\n",
    "#         if data2[j][k] >= 0.5:\n",
    "#             data2[j][k] = 1\n",
    "#         else:\n",
    "#             data2[j][k] = 0\n",
    "            \n",
    "# print(data2)\n",
    "# print(len(data2))\n",
    "\n",
    "# np.random.seed(seed_num)\n",
    "# test = np.array([1, 0]) # 128 pounds, 63 inches\n",
    "# # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "# # print(network.feedforward2(W1,W2,test))\n",
    "# print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "# test = np.array([0, 0])  # 155 pounds, 68 inches\n",
    "# # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "# # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "# # print(network.feedforward2(W1,W2,test))\n",
    "# print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "# test = np.array([0, 1])  # 155 pounds, 68 inches\n",
    "# # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "# # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "# # print(network.feedforward2(W1,W2,test))\n",
    "# print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "# test = np.array([1, 1])  # 155 pounds, 68 inches\n",
    "# # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "# # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "# # print(network.feedforward2(W1,W2,test))\n",
    "# print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "\n",
    "# # Weights\n",
    "# w7 = np.random.normal()\n",
    "# w8 = np.random.normal()\n",
    "\n",
    "# # Biases\n",
    "# b1 = np.random.normal()\n",
    "# b2 = np.random.normal()\n",
    "# b3 = np.random.normal()\n",
    "\n",
    "np.random.seed(seed_num)\n",
    "for _ in range(0,2):\n",
    "    W1,W2,w7,w8,b1,b2,b3,hl2 = train_fit_2(data,all_y_trues,w7,w8,b1,b2,b3)\n",
    "    \n",
    "# np.random.seed(seed_num)\n",
    "# test = np.array([1, 0]) # 128 pounds, 63 inches\n",
    "# # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "# # print(network.feedforward2(W1,W2,test))\n",
    "# print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data2))\n",
    "# test = np.array([0, 0])  # 155 pounds, 68 inches\n",
    "# # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "# # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "# # print(network.feedforward2(W1,W2,test))\n",
    "# print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data2))\n",
    "# test = np.array([0, 1])  # 155 pounds, 68 inches\n",
    "# # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "# # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "# # print(network.feedforward2(W1,W2,test))\n",
    "# print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data2))\n",
    "# test = np.array([1, 1])  # 155 pounds, 68 inches\n",
    "# # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "# # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "# # print(network.feedforward2(W1,W2,test))\n",
    "# print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make some predictions\n",
    "if len(X_xor) == 1:\n",
    "    test = np.array([0]) # 128 pounds, 63 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([1])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([1])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([0])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    # # print(\"Emily: %.3f\" % network.feedforward(emily)) # 0.951 - F\n",
    "    # # print(\"Frank: %.3f\" % network.feedforward(frank)) # 0.039 - Mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9895982557150717\n",
      "0.006559287773534918\n",
      "0.9897379282823295\n",
      "0.012489409165534336\n"
     ]
    }
   ],
   "source": [
    "# # # Make some predictions\n",
    "if len(X_xor) == 2:\n",
    "#     np.random.seed(seed_num)\n",
    "    test = np.array([1, 0]) # 128 pounds, 63 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    # print(network.feedforward2(W1,W2,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([0, 0])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "    # print(network.feedforward2(W1,W2,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([0, 1])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "    # print(network.feedforward2(W1,W2,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([1, 1])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "    # print(network.feedforward2(W1,W2,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "\n",
    "# # # # network.feedforward2(W1,W2,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_xor) == 5:\n",
    "    # np.random.seed(seed_num)\n",
    "    # for _ in range(0,2):\n",
    "    #     W1,W2,w7,w8,b1,b2,b3 = train_fit(data_5,all_y_trues,w7,w8,b1,b2,b3)\n",
    "\n",
    "    # # Make some predictions\n",
    "    # np.random.seed(7)\n",
    "    np.random.seed(seed_num)\n",
    "    test = np.array([1, 0, 1, 0, 0]) # 128 pounds, 63 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([0, 0, 0, 0, 0])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([0, 1, 1, 0, 1])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))\n",
    "    test = np.array([1, 1, 1, 1,1])  # 155 pounds, 68 inches\n",
    "    # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "    print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Make some predictions\n",
    "# if len(X_xor) == 3:\n",
    "#     np.random.seed(seed_num)\n",
    "#     test = np.array([1, 0, 1]) # 128 pounds, 63 inches\n",
    "#     # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "#     # print(network.feedforward2(W1,W2,test))\n",
    "#     print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     test = np.array([0, 0, 0])  # 155 pAounds, 68 inches\n",
    "#     # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "#     # print(network.feedforward2(W1,W2,test))\n",
    "#     print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     test = np.array([0, 0, 1])  # 155 pounds, 68 inches\n",
    "#     # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "#     # print(network.feedforward2(W1,W2,test))\n",
    "#     print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     test = np.array([1, 1, 1])  # 155 pounds, 68 inches\n",
    "#     # print(feedforward(w1,w2,w3,w4,w5,w6,w7,w8,b1,b2,b3,test))\n",
    "#     # print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     # print(network.feedforward2(W1,W2,test))\n",
    "#     print(feedforward2(W1,W2,w7,w8,b1,b2,b3,test))\n",
    "#     # # print(\"Emily: %.3f\" % network.feedforward(emily)) # 0.951 - F\n",
    "#     # # print(\"Frank: %.3f\" % network.feedforward(frank)) # 0.039 - Mx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
