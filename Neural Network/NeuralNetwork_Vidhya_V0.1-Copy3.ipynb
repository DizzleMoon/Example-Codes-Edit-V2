{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Iterable, Tuple, Callable\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "# import pygal\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import urllib.request\n",
    "import requests\n",
    "import curl\n",
    "import pycurl\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "# from IPython import qt\n",
    "from matplotlib.pyplot import figure\n",
    "from py.xml import raw\n",
    "from requests.api import get\n",
    "from matplotlib import pyplot as plt\n",
    "# from scratch.working_with_data import rescale\n",
    "# from scratch.multiple_regression import least_squares_fit, predict\n",
    "# from scratch.gradient_descent import gradient_step\n",
    "\n",
    "# from stats import mean, median, de_mean, standard_deviation, correlation\n",
    "# from gradient_descent import minimize_stochastic, maximize_stochastic, maximize_batch\n",
    "# from vector import dot, vector_add\n",
    "# from normal import normal_cdf\n",
    "# from matrix import make_matrix, get_column, shape, matrix_multiply\n",
    "# from logistic_regression import *\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from functools import partial, reduce\n",
    "\n",
    "from scipy.optimize import fmin_tnc\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from typing import*\n",
    "\n",
    "from collections import*\n",
    "# from scipy import*\n",
    "from sklearn.metrics import*\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "# bltin_sum = np.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# def add(a, b): return a + b\n",
    "\n",
    "Vector = List[float]\n",
    "\n",
    "def vector_sum(vectors):\n",
    "    \"\"\"Sums all corresponding elements\"\"\"\n",
    "    # Check that vectors is not empty\n",
    "    assert vectors, \"no vectors provided!\"\n",
    "\n",
    "    # Check the vectors are all the same size\n",
    "    num_elements = len(vectors[0])\n",
    "    assert all(len(v) == num_elements for v in vectors), \"different sizes!\"\n",
    "\n",
    "    # the i-th element of the result is the sum of every vector[i]\n",
    "    return [sum(vector[i] for vector in vectors)\n",
    "            for i in range(num_elements)]\n",
    "\n",
    "def scalar_multiply(c , v):\n",
    "    \"\"\"Multiplies every element by c\"\"\"\n",
    "    return [c * v_i for v_i in v]\n",
    "\n",
    "def vector_mean(vectors):\n",
    "    \"\"\"Computes the element-wise average\"\"\"\n",
    "    n = len(vectors)\n",
    "    m = sum(vectors,axis=0)\n",
    "    vec_mean = np.multiply(1/n,m)\n",
    "    return vec_mean\n",
    "\n",
    "def de_mean(xs):\n",
    "    \"\"\"Translate xs by subtracting its mean (so the result has mean 0)\"\"\"\n",
    "    x_bar = np.mean(xs)\n",
    "    d_mean = [x - x_bar for x in xs]\n",
    "    return d_mean\n",
    "\n",
    "def dot(v, w):\n",
    "    \"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be same length\"\n",
    "\n",
    "#     return np.sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "#     gen = \n",
    "    return np.sum(np.fromiter((v_i * w_i for v_i, w_i in zip(v, w)),float))\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    \"\"\"Returns v_1 * v_1 + ... + v_n * v_n\"\"\"\n",
    "    return dot(v, v)\n",
    "\n",
    "def variance(xs):\n",
    "    \"\"\"Almost the average squared deviation from the mean\"\"\"\n",
    "    assert len(xs) >= 2, \"variance requires at least two elements\"\n",
    "\n",
    "    n = len(xs)\n",
    "    deviations = de_mean(xs)\n",
    "    vari = sum_of_squares(deviations)/(n-1)\n",
    "    return vari\n",
    "\n",
    "# Standard deviation                        \n",
    "def standard_deviation(xs):\n",
    "    \"\"\"The standard deviation is the square root of the variance\"\"\"\n",
    "    std_dev = np.sqrt(variance(xs)) \n",
    "    return std_dev\n",
    "\n",
    "def scale(data):\n",
    "    \"\"\"returns the mean and standard deviation for each position\"\"\"\n",
    "    dim = data.shape[0]\n",
    "    \n",
    "    # Vector Mean\n",
    "#     n = len(data)\n",
    "#     m = np.sum(data,axis=0)\n",
    "#     means = np.multiply(1/n,m)\n",
    "    means = vector_mean(data)\n",
    "    \n",
    "    # Standard Deviaiton\n",
    "    stdevs = [standard_deviation([vector[i] for vector in data])\n",
    "              for i in range(dim)]\n",
    "    return means,stdevs\n",
    "\n",
    "def rescale(data):\n",
    "    \"\"\"\n",
    "    Rescales the input data so that each position has\n",
    "    mean 0 and standard deviation 1. (Leaves a position\n",
    "    as is if its standard deviation is 0.)\n",
    "    \"\"\"\n",
    "    dim = data.shape[0]\n",
    "    means, stdevs = scale(data)\n",
    "    \n",
    "    means = list(means)\n",
    "    stdevs = list(stdevs)\n",
    "\n",
    "    # Make a copy of each vector\n",
    "    rescaled = [v[:] for v in data]\n",
    "    v0 = []\n",
    "    for v in rescaled:\n",
    "        v = list(v)\n",
    "        for i in range(dim):\n",
    "            if stdevs[i] > 0:\n",
    "                v[i] = (v[i] - means[i]) / stdevs[i]\n",
    "        v0.append(v)\n",
    "\n",
    "    return v0\n",
    "\n",
    "def gradient_step(v, gradient, step_size):\n",
    "    \"\"\"Moves `step_size` in the `gradient` direction from `v`\"\"\"\n",
    "    assert len(v) == len(gradient)\n",
    "    step = scalar_multiply(step_size, gradient)\n",
    "    grad_step = np.add(v,step)\n",
    "    return grad_step\n",
    "\n",
    "# def predict(alpha, beta, x_i):\n",
    "#     pred = beta * x_i + alpha\n",
    "#     return pred\n",
    "\n",
    "# def error(x, y, beta):\n",
    "#     \"\"\"\n",
    "#     The error from predicting beta * x_i + alpha\n",
    "#     when the actual value is y_i\n",
    "#     \"\"\"\n",
    "#     err_fin = predict(alpha, beta, x_i) - y_i\n",
    "#     return err_fin\n",
    "\n",
    "def predict(x, beta):\n",
    "    \"\"\"assumes that the first element of x is 1\"\"\"\n",
    "    return dot(x, beta)\n",
    "\n",
    "def error(x, y, beta):\n",
    "    return predict(x, beta) - y \n",
    "\n",
    "def sqerror_gradient(x, y, beta):\n",
    "    err = error(x, y, beta)\n",
    "    err_fin = [2 * err * x_i for x_i in x]\n",
    "    return err_fin\n",
    "\n",
    "def least_squares_fit(xs, ys, learning_rate = 0.001, num_steps = 1000, batch_size = 1):\n",
    "    \"\"\"\n",
    "    Find the beta that minimizes the sum of squared errors\n",
    "    assuming the model y = dot(x, beta).\n",
    "    \"\"\"\n",
    "    # Start with a random guess\n",
    "    guess = [np.random.random() for _ in xs[0]]\n",
    "\n",
    "    for _ in tqdm.trange(num_steps, desc=\"least squares fit\"):\n",
    "        for start in range(0, len(xs), batch_size):\n",
    "            batch_xs = xs[start:start+batch_size]\n",
    "            batch_ys = ys[start:start+batch_size]\n",
    "\n",
    "            gradient = vector_mean([sqerror_gradient(x, y, guess)\n",
    "                                    for x, y in zip(batch_xs, batch_ys)])\n",
    "            guess = gradient_step(guess, gradient, -learning_rate)\n",
    "\n",
    "    return guess\n",
    "\n",
    "def logistic(x):\n",
    "    return 1.0 / (1 + math.exp(-x))\n",
    "\n",
    "def logistic_prime(x):\n",
    "    y = logistic(x)\n",
    "    return y * (1 - y)\n",
    "\n",
    "def _negative_log_likelihood(x, y, beta):\n",
    "    \"\"\"The negative log likelihood for one data point\"\"\" \n",
    "    if y == 1:\n",
    "        return -math.log(logistic(dot(x, beta)))\n",
    "    else:\n",
    "        return -math.log(1 - logistic(dot(x, beta)))\n",
    "    \n",
    "def negative_log_likelihood(xs, ys, beta):\n",
    "    return sum(_negative_log_likelihood(x, y, beta)\n",
    "               for x, y in zip(xs, ys))\n",
    "\n",
    "def _negative_log_partial_j(x, y, beta, j):\n",
    "    \"\"\"\n",
    "    The jth partial derivative for one data point.\n",
    "    Here i is the index of the data point.\n",
    "    \"\"\"\n",
    "    return -(y - logistic(dot(x, beta))) * x[j]\n",
    "\n",
    "def _negative_log_gradient(x, y, beta):\n",
    "    \"\"\"\n",
    "    The gradient for one data point.\n",
    "    \"\"\"\n",
    "    return [_negative_log_partial_j(x, y, beta, j)\n",
    "            for j in range(len(beta))]\n",
    "\n",
    "def negative_log_gradient(xs, ys,beta):\n",
    "    return vector_sum([_negative_log_gradient(x, y, beta)\n",
    "                       for x, y in zip(xs, ys)])\n",
    "\n",
    "def split_data(data, prob):\n",
    "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    data = data[:]                    # Make a shallow copy\n",
    "    random.shuffle(data)              # because shuffle modifies the list.\n",
    "    cut = int(len(data) * prob)       # Use prob to find a cutoff\n",
    "    return data[:cut], data[cut:]     # and split the shuffled list there.\n",
    "\n",
    "def train_test_split(xs, ys, test_pct):\n",
    "     # Generate the indices and split them\n",
    "    idxs = [i for i in range(len(xs))]\n",
    "    train_idxs, test_idxs = split_data(idxs, 1 - test_pct)\n",
    "\n",
    "    return ([xs[i] for i in train_idxs],  # x_train \n",
    "            [xs[i] for i in test_idxs],   # x_test\n",
    "            [ys[i] for i in train_idxs],  # y_train\n",
    "            [ys[i] for i in test_idxs])   # y_test\n",
    "                                                                \n",
    "def step_function(x: float) -> float:\n",
    "    return 1.0 if x >= 0 else 0.0\n",
    "\n",
    "def sigmoid(t: float) -> float: \n",
    "    return 1 / (1 + math.exp(-t))\n",
    "\n",
    "# Gradient Descent - step\n",
    "def gradient_step(v: Vector, gradient: Vector, step_size: float):\n",
    "    \"\"\"Moves `step_size` in the `gradient` direction from `v`\"\"\"\n",
    "    assert len(v) == len(gradient)\n",
    "    step = scalar_multiply(step_size, gradient)\n",
    "    return add(v, step)\n",
    "\n",
    "def sum_of_squares_gradient(v: Vector) -> Vector:\n",
    "    return [2 * v_i for v_i in v]\n",
    "\n",
    "def squared_distance(v: Vector, w: Vector) -> float:\n",
    "    \"\"\"Computes (v_1 - w_1) ** 2 + ... + (v_n - w_n) ** 2\"\"\"\n",
    "    return sum_of_squares(subtract(v, w))\n",
    "\n",
    "def distance(v: Vector, w: Vector) -> float:\n",
    "    \"\"\"Computes the distance between v and w\"\"\"\n",
    "    return math.sqrt(squared_distance(v, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Input:\n",
      "[[1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [0 1 0 1]]\n",
      "\n",
      " Actual Output:\n",
      "[[1]\n",
      " [1]\n",
      " [0]]\n",
      "[[0.0541031  0.82769418 0.13996087]\n",
      " [0.75211613 0.37768333 0.09921063]\n",
      " [0.9894794  0.52692834 0.34955643]\n",
      " [0.36361069 0.97097205 0.23855819]]\n",
      "[[0.96305879 0.60251859 0.80843332]]\n",
      "[[0.13101727]\n",
      " [0.04732425]\n",
      " [0.89437447]]\n",
      "[[0.69466741]]\n",
      "\n",
      " Output from the model:\n",
      "[[0.9999061 ]\n",
      " [0.99363358]\n",
      " [0.06999094]]\n"
     ]
    }
   ],
   "source": [
    "# importing the library\n",
    "import numpy as np\n",
    "\n",
    "# creating the input array\n",
    "X=np.array([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "print ('\\n Input:')\n",
    "print(X)\n",
    "\n",
    "# creating the output array\n",
    "y=np.array([[1],[1],[0]])\n",
    "print ('\\n Actual Output:')\n",
    "print(y)\n",
    "\n",
    "# defining the Sigmoid Function\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# derivative of Sigmoid Function\n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# initializing the variables\n",
    "epoch=5000 # number of training iterations\n",
    "lr=0.1 # learning rate\n",
    "inputlayer_neurons = X.shape[1] # number of features in data set\n",
    "hiddenlayer_neurons = 3 # number of hidden layers neurons\n",
    "output_neurons = 1 # number of neurons at output layer\n",
    "\n",
    "# print(\"X\", X.shape[1])\n",
    "\n",
    "# initializing weight and bias\n",
    "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
    "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
    "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
    "bout=np.random.uniform(size=(1,output_neurons))\n",
    "\n",
    "print(wh)\n",
    "print(bh)\n",
    "print(wout)\n",
    "print(bout)\n",
    "\n",
    "outputs = []\n",
    "\n",
    "# # training the model\n",
    "for i in range(epoch):\n",
    "\n",
    "    #Forward Propogation\n",
    "    hidden_layer_input1=np.dot(X,wh)\n",
    "    hidden_layer_input=hidden_layer_input1 + bh\n",
    "    hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "    output_layer_input1=np.dot(hiddenlayer_activations,wout)\n",
    "    output_layer_input= output_layer_input1+ bout\n",
    "    output = sigmoid(output_layer_input)\n",
    "    outputs.append(output)\n",
    "    \n",
    "    # Gradient Descent\n",
    "\n",
    "#     for epoch in range(100):\n",
    "    grad = sum_of_squares_gradient(output) \n",
    "    output2 = gradient_step(output, grad, -0.01)  \n",
    "    grad = sum_of_squares_gradient(hiddenlayer_activations) \n",
    "    output3 = gradient_step(hiddenlayer_activations, grad, -0.01)   \n",
    "#     print(output)\n",
    "\n",
    "    \n",
    "\n",
    "    #Backpropagation\n",
    "    E = y-output\n",
    "#     slope_output_layer = derivatives_sigmoid(output)\n",
    "#     slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "    d_output = E * output2\n",
    "    Error_at_hidden_layer = d_output.dot(wout.T)\n",
    "    d_hiddenlayer = Error_at_hidden_layer * output3\n",
    "    wout += hiddenlayer_activations.T.dot(d_output) *lr\n",
    "    bout += np.sum(d_output, axis=0,keepdims=True) *lr\n",
    "    wh += X.T.dot(d_hiddenlayer) *lr\n",
    "    bh += np.sum(d_hiddenlayer, axis=0,keepdims=True) *lr\n",
    "\n",
    "print ('\\n Output from the model:')\n",
    "print (output)\n",
    "# print(slope_output_layer)\n",
    "# print(slope_hidden_layer)\n",
    "# print(output2)\n",
    "# print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = output.T.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.80900162]\n",
      " [0.81475238]\n",
      " [0.80574116]]\n",
      "1 [[0.79282159]\n",
      " [0.79845733]\n",
      " [0.78962634]]\n",
      "2 [[0.77696516]\n",
      " [0.78248819]\n",
      " [0.77383381]]\n",
      "3 [[0.76142586]\n",
      " [0.76683842]\n",
      " [0.75835713]]\n",
      "4 [[0.74619734]\n",
      " [0.75150166]\n",
      " [0.74318999]]\n",
      "5 [[0.73127339]\n",
      " [0.73647162]\n",
      " [0.72832619]]\n",
      "6 [[0.71664792]\n",
      " [0.72174219]\n",
      " [0.71375967]]\n",
      "7 [[0.70231497]\n",
      " [0.70730735]\n",
      " [0.69948447]]\n",
      "8 [[0.68826867]\n",
      " [0.6931612 ]\n",
      " [0.68549478]]\n",
      "9 [[0.67450329]\n",
      " [0.67929798]\n",
      " [0.67178489]]\n",
      "10 [[0.66101323]\n",
      " [0.66571202]\n",
      " [0.65834919]]\n",
      "11 [[0.64779296]\n",
      " [0.65239778]\n",
      " [0.64518221]]\n",
      "12 [[0.6348371 ]\n",
      " [0.63934982]\n",
      " [0.63227856]]\n",
      "13 [[0.62214036]\n",
      " [0.62656282]\n",
      " [0.61963299]]\n",
      "14 [[0.60969755]\n",
      " [0.61403157]\n",
      " [0.60724033]]\n",
      "15 [[0.5975036 ]\n",
      " [0.60175094]\n",
      " [0.59509553]]\n",
      "16 [[0.58555353]\n",
      " [0.58971592]\n",
      " [0.58319361]]\n",
      "17 [[0.57384246]\n",
      " [0.5779216 ]\n",
      " [0.57152974]]\n",
      "18 [[0.56236561]\n",
      " [0.56636317]\n",
      " [0.56009915]]\n",
      "19 [[0.5511183 ]\n",
      " [0.5550359 ]\n",
      " [0.54889716]]\n",
      "20 [[0.54009593]\n",
      " [0.54393519]\n",
      " [0.53791922]]\n",
      "21 [[0.52929401]\n",
      " [0.53305648]\n",
      " [0.52716084]]\n",
      "22 [[0.51870813]\n",
      " [0.52239535]\n",
      " [0.51661762]]\n",
      "23 [[0.50833397]\n",
      " [0.51194744]\n",
      " [0.50628527]]\n",
      "24 [[0.49816729]\n",
      " [0.5017085 ]\n",
      " [0.49615956]]\n",
      "25 [[0.48820395]\n",
      " [0.49167433]\n",
      " [0.48623637]]\n",
      "26 [[0.47843987]\n",
      " [0.48184084]\n",
      " [0.47651164]]\n",
      "27 [[0.46887107]\n",
      " [0.47220402]\n",
      " [0.46698141]]\n",
      "28 [[0.45949365]\n",
      " [0.46275994]\n",
      " [0.45764178]]\n",
      "29 [[0.45030378]\n",
      " [0.45350474]\n",
      " [0.44848895]]\n",
      "30 [[0.4412977 ]\n",
      " [0.44443465]\n",
      " [0.43951917]]\n",
      "31 [[0.43247175]\n",
      " [0.43554596]\n",
      " [0.43072878]]\n",
      "32 [[0.42382231]\n",
      " [0.42683504]\n",
      " [0.42211421]]\n",
      "33 [[0.41534586]\n",
      " [0.41829834]\n",
      " [0.41367192]]\n",
      "34 [[0.40703895]\n",
      " [0.40993237]\n",
      " [0.40539849]]\n",
      "35 [[0.39889817]\n",
      " [0.40173372]\n",
      " [0.39729052]]\n",
      "36 [[0.39092021]\n",
      " [0.39369905]\n",
      " [0.38934471]]\n",
      "37 [[0.3831018 ]\n",
      " [0.38582507]\n",
      " [0.38155781]]\n",
      "38 [[0.37543976]\n",
      " [0.37810856]\n",
      " [0.37392666]]\n",
      "39 [[0.36793097]\n",
      " [0.37054639]\n",
      " [0.36644812]]\n",
      "40 [[0.36057235]\n",
      " [0.36313547]\n",
      " [0.35911916]]\n",
      "41 [[0.3533609 ]\n",
      " [0.35587276]\n",
      " [0.35193678]]\n",
      "42 [[0.34629369]\n",
      " [0.3487553 ]\n",
      " [0.34489804]]\n",
      "43 [[0.33936781]\n",
      " [0.3417802 ]\n",
      " [0.33800008]]\n",
      "44 [[0.33258046]\n",
      " [0.33494459]\n",
      " [0.33124008]]\n",
      "45 [[0.32592885]\n",
      " [0.3282457 ]\n",
      " [0.32461528]]\n",
      "46 [[0.31941027]\n",
      " [0.32168079]\n",
      " [0.31812297]]\n",
      "47 [[0.31302206]\n",
      " [0.31524717]\n",
      " [0.31176051]]\n",
      "48 [[0.30676162]\n",
      " [0.30894223]\n",
      " [0.3055253 ]]\n",
      "49 [[0.30062639]\n",
      " [0.30276338]\n",
      " [0.2994148 ]]\n",
      "50 [[0.29461386]\n",
      " [0.29670811]\n",
      " [0.2934265 ]]\n",
      "51 [[0.28872159]\n",
      " [0.29077395]\n",
      " [0.28755797]]\n",
      "52 [[0.28294715]\n",
      " [0.28495847]\n",
      " [0.28180681]]\n",
      "53 [[0.27728821]\n",
      " [0.2792593 ]\n",
      " [0.27617067]]\n",
      "54 [[0.27174245]\n",
      " [0.27367412]\n",
      " [0.27064726]]\n",
      "55 [[0.2663076 ]\n",
      " [0.26820064]\n",
      " [0.26523432]]\n",
      "56 [[0.26098145]\n",
      " [0.26283662]\n",
      " [0.25992963]]\n",
      "57 [[0.25576182]\n",
      " [0.25757989]\n",
      " [0.25473104]]\n",
      "58 [[0.25064658]\n",
      " [0.25242829]\n",
      " [0.24963642]]\n",
      "59 [[0.24563365]\n",
      " [0.24737973]\n",
      " [0.24464369]]\n",
      "60 [[0.24072098]\n",
      " [0.24243213]\n",
      " [0.23975081]]\n",
      "61 [[0.23590656]\n",
      " [0.23758349]\n",
      " [0.2349558 ]]\n",
      "62 [[0.23118842]\n",
      " [0.23283182]\n",
      " [0.23025668]]\n",
      "63 [[0.22656466]\n",
      " [0.22817518]\n",
      " [0.22565155]]\n",
      "64 [[0.22203336]\n",
      " [0.22361168]\n",
      " [0.22113852]]\n",
      "65 [[0.2175927 ]\n",
      " [0.21913945]\n",
      " [0.21671575]]\n",
      "66 [[0.21324084]\n",
      " [0.21475666]\n",
      " [0.21238143]]\n",
      "67 [[0.20897603]\n",
      " [0.21046152]\n",
      " [0.2081338 ]]\n",
      "68 [[0.2047965 ]\n",
      " [0.20625229]\n",
      " [0.20397113]]\n",
      "69 [[0.20070057]\n",
      " [0.20212725]\n",
      " [0.1998917 ]]\n",
      "70 [[0.19668656]\n",
      " [0.1980847 ]\n",
      " [0.19589387]]\n",
      "71 [[0.19275283]\n",
      " [0.19412301]\n",
      " [0.19197599]]\n",
      "72 [[0.18889778]\n",
      " [0.19024055]\n",
      " [0.18813647]]\n",
      "73 [[0.18511982]\n",
      " [0.18643574]\n",
      " [0.18437374]]\n",
      "74 [[0.18141742]\n",
      " [0.18270702]\n",
      " [0.18068627]]\n",
      "75 [[0.17778907]\n",
      " [0.17905288]\n",
      " [0.17707254]]\n",
      "76 [[0.17423329]\n",
      " [0.17547182]\n",
      " [0.17353109]]\n",
      "77 [[0.17074863]\n",
      " [0.17196239]\n",
      " [0.17006047]]\n",
      "78 [[0.16733365]\n",
      " [0.16852314]\n",
      " [0.16665926]]\n",
      "79 [[0.16398698]\n",
      " [0.16515268]\n",
      " [0.16332608]]\n",
      "80 [[0.16070724]\n",
      " [0.16184962]\n",
      " [0.16005955]]\n",
      "81 [[0.1574931 ]\n",
      " [0.15861263]\n",
      " [0.15685836]]\n",
      "82 [[0.15434324]\n",
      " [0.15544038]\n",
      " [0.1537212 ]]\n",
      "83 [[0.15125637]\n",
      " [0.15233157]\n",
      " [0.15064677]]\n",
      "84 [[0.14823124]\n",
      " [0.14928494]\n",
      " [0.14763384]]\n",
      "85 [[0.14526662]\n",
      " [0.14629924]\n",
      " [0.14468116]]\n",
      "86 [[0.14236129]\n",
      " [0.14337326]\n",
      " [0.14178754]]\n",
      "87 [[0.13951406]\n",
      " [0.14050579]\n",
      " [0.13895179]]\n",
      "88 [[0.13672378]\n",
      " [0.13769568]\n",
      " [0.13617275]]\n",
      "89 [[0.1339893 ]\n",
      " [0.13494176]\n",
      " [0.1334493 ]]\n",
      "90 [[0.13130952]\n",
      " [0.13224293]\n",
      " [0.13078031]]\n",
      "91 [[0.12868333]\n",
      " [0.12959807]\n",
      " [0.1281647 ]]\n",
      "92 [[0.12610966]\n",
      " [0.12700611]\n",
      " [0.12560141]]\n",
      "93 [[0.12358747]\n",
      " [0.12446598]\n",
      " [0.12308938]]\n",
      "94 [[0.12111572]\n",
      " [0.12197666]\n",
      " [0.12062759]]\n",
      "95 [[0.1186934 ]\n",
      " [0.11953713]\n",
      " [0.11821504]]\n",
      "96 [[0.11631954]\n",
      " [0.11714639]\n",
      " [0.11585074]]\n",
      "97 [[0.11399314]\n",
      " [0.11480346]\n",
      " [0.11353373]]\n",
      "98 [[0.11171328]\n",
      " [0.11250739]\n",
      " [0.11126305]]\n",
      "99 [[0.10947902]\n",
      " [0.11025724]\n",
      " [0.10903779]]\n",
      "100 [[0.10728944]\n",
      " [0.1080521 ]\n",
      " [0.10685703]]\n",
      "101 [[0.10514365]\n",
      " [0.10589106]\n",
      " [0.10471989]]\n",
      "102 [[0.10304077]\n",
      " [0.10377324]\n",
      " [0.1026255 ]]\n",
      "103 [[0.10097996]\n",
      " [0.10169777]\n",
      " [0.10057299]]\n",
      "104 [[0.09896036]\n",
      " [0.09966382]\n",
      " [0.09856153]]\n",
      "105 [[0.09698115]\n",
      " [0.09767054]\n",
      " [0.0965903 ]]\n",
      "106 [[0.09504153]\n",
      " [0.09571713]\n",
      " [0.09465849]]\n",
      "107 [[0.0931407 ]\n",
      " [0.09380279]\n",
      " [0.09276532]]\n",
      "108 [[0.09127788]\n",
      " [0.09192673]\n",
      " [0.09091001]]\n",
      "109 [[0.08945233]\n",
      " [0.0900882 ]\n",
      " [0.08909181]]\n",
      "110 [[0.08766328]\n",
      " [0.08828643]\n",
      " [0.08730998]]\n",
      "111 [[0.08591002]\n",
      " [0.0865207 ]\n",
      " [0.08556378]]\n",
      "112 [[0.08419181]\n",
      " [0.08479029]\n",
      " [0.0838525 ]]\n",
      "113 [[0.08250798]\n",
      " [0.08309448]\n",
      " [0.08217545]]\n",
      "114 [[0.08085782]\n",
      " [0.08143259]\n",
      " [0.08053194]]\n",
      "115 [[0.07924066]\n",
      " [0.07980394]\n",
      " [0.0789213 ]]\n",
      "116 [[0.07765585]\n",
      " [0.07820786]\n",
      " [0.07734288]]\n",
      "117 [[0.07610273]\n",
      " [0.07664371]\n",
      " [0.07579602]]\n",
      "118 [[0.07458068]\n",
      " [0.07511083]\n",
      " [0.0742801 ]]\n",
      "119 [[0.07308906]\n",
      " [0.07360862]\n",
      " [0.0727945 ]]\n",
      "120 [[0.07162728]\n",
      " [0.07213644]\n",
      " [0.07133861]]\n",
      "121 [[0.07019474]\n",
      " [0.07069371]\n",
      " [0.06991184]]\n",
      "122 [[0.06879084]\n",
      " [0.06927984]\n",
      " [0.0685136 ]]\n",
      "123 [[0.06741503]\n",
      " [0.06789424]\n",
      " [0.06714333]]\n",
      "124 [[0.06606673]\n",
      " [0.06653636]\n",
      " [0.06580046]]\n",
      "125 [[0.06474539]\n",
      " [0.06520563]\n",
      " [0.06448445]]\n",
      "126 [[0.06345048]\n",
      " [0.06390152]\n",
      " [0.06319476]]\n",
      "127 [[0.06218147]\n",
      " [0.06262349]\n",
      " [0.06193087]]\n",
      "128 [[0.06093784]\n",
      " [0.06137102]\n",
      " [0.06069225]]\n",
      "129 [[0.05971909]\n",
      " [0.0601436 ]\n",
      " [0.0594784 ]]\n",
      "130 [[0.0585247 ]\n",
      " [0.05894073]\n",
      " [0.05828884]]\n",
      "131 [[0.05735421]\n",
      " [0.05776191]\n",
      " [0.05712306]]\n",
      "132 [[0.05620713]\n",
      " [0.05660667]\n",
      " [0.0559806 ]]\n",
      "133 [[0.05508298]\n",
      " [0.05547454]\n",
      " [0.05486099]]\n",
      "134 [[0.05398132]\n",
      " [0.05436505]\n",
      " [0.05376377]]\n",
      "135 [[0.0529017 ]\n",
      " [0.05327775]\n",
      " [0.05268849]]\n",
      "136 [[0.05184366]\n",
      " [0.05221219]\n",
      " [0.05163472]]\n",
      "137 [[0.05080679]\n",
      " [0.05116795]\n",
      " [0.05060203]]\n",
      "138 [[0.04979065]\n",
      " [0.05014459]\n",
      " [0.04958999]]\n",
      "139 [[0.04879484]\n",
      " [0.0491417 ]\n",
      " [0.04859819]]\n",
      "140 [[0.04781894]\n",
      " [0.04815886]\n",
      " [0.04762622]]\n",
      "141 [[0.04686257]\n",
      " [0.04719569]\n",
      " [0.0466737 ]]\n",
      "142 [[0.04592531]\n",
      " [0.04625177]\n",
      " [0.04574023]]\n",
      "143 [[0.04500681]\n",
      " [0.04532674]\n",
      " [0.04482542]]\n",
      "144 [[0.04410667]\n",
      " [0.0444202 ]\n",
      " [0.04392891]]\n",
      "145 [[0.04322454]\n",
      " [0.0435318 ]\n",
      " [0.04305033]]\n",
      "146 [[0.04236005]\n",
      " [0.04266116]\n",
      " [0.04218933]]\n",
      "147 [[0.04151285]\n",
      " [0.04180794]\n",
      " [0.04134554]]\n",
      "148 [[0.04068259]\n",
      " [0.04097178]\n",
      " [0.04051863]]\n",
      "149 [[0.03986894]\n",
      " [0.04015235]\n",
      " [0.03970826]]\n",
      "150 [[0.03907156]\n",
      " [0.0393493 ]\n",
      " [0.03891409]]\n",
      "151 [[0.03829013]\n",
      " [0.03856231]\n",
      " [0.03813581]]\n",
      "152 [[0.03752433]\n",
      " [0.03779107]\n",
      " [0.03737309]]\n",
      "153 [[0.03677384]\n",
      " [0.03703524]\n",
      " [0.03662563]]\n",
      "154 [[0.03603836]\n",
      " [0.03629454]\n",
      " [0.03589312]]\n",
      "155 [[0.0353176 ]\n",
      " [0.03556865]\n",
      " [0.03517526]]\n",
      "156 [[0.03461124]\n",
      " [0.03485728]\n",
      " [0.03447175]]\n",
      "157 [[0.03391902]\n",
      " [0.03416013]\n",
      " [0.03378232]]\n",
      "158 [[0.03324064]\n",
      " [0.03347693]\n",
      " [0.03310667]]\n",
      "159 [[0.03257583]\n",
      " [0.03280739]\n",
      " [0.03244454]]\n",
      "160 [[0.03192431]\n",
      " [0.03215124]\n",
      " [0.03179565]]\n",
      "161 [[0.03128582]\n",
      " [0.03150822]\n",
      " [0.03115973]]\n",
      "162 [[0.03066011]\n",
      " [0.03087805]\n",
      " [0.03053654]]\n",
      "163 [[0.0300469 ]\n",
      " [0.03026049]\n",
      " [0.02992581]]\n",
      "164 [[0.02944597]\n",
      " [0.02965528]\n",
      " [0.02932729]]\n",
      "165 [[0.02885705]\n",
      " [0.02906218]\n",
      " [0.02874075]]\n",
      "166 [[0.02827991]\n",
      " [0.02848093]\n",
      " [0.02816593]]\n",
      "167 [[0.02771431]\n",
      " [0.02791131]\n",
      " [0.02760261]]\n",
      "168 [[0.02716002]\n",
      " [0.02735309]\n",
      " [0.02705056]]\n",
      "169 [[0.02661682]\n",
      " [0.02680603]\n",
      " [0.02650955]]\n",
      "170 [[0.02608448]\n",
      " [0.02626991]\n",
      " [0.02597936]]\n",
      "171 [[0.02556279]\n",
      " [0.02574451]\n",
      " [0.02545977]]\n",
      "172 [[0.02505154]\n",
      " [0.02522962]\n",
      " [0.02495058]]\n",
      "173 [[0.02455051]\n",
      " [0.02472502]\n",
      " [0.02445156]]\n",
      "174 [[0.0240595 ]\n",
      " [0.02423052]\n",
      " [0.02396253]]\n",
      "175 [[0.02357831]\n",
      " [0.02374591]\n",
      " [0.02348328]]\n",
      "176 [[0.02310674]\n",
      " [0.023271  ]\n",
      " [0.02301362]]\n",
      "177 [[0.02264461]\n",
      " [0.02280558]\n",
      " [0.02255334]]\n",
      "178 [[0.02219172]\n",
      " [0.02234946]\n",
      " [0.02210228]]\n",
      "179 [[0.02174788]\n",
      " [0.02190247]\n",
      " [0.02166023]]\n",
      "180 [[0.02131292]\n",
      " [0.02146443]\n",
      " [0.02122703]]\n",
      "181 [[0.02088666]\n",
      " [0.02103514]\n",
      " [0.02080249]]\n",
      "182 [[0.02046893]\n",
      " [0.02061443]\n",
      " [0.02038644]]\n",
      "183 [[0.02005955]\n",
      " [0.02020215]\n",
      " [0.01997871]]\n",
      "184 [[0.01965836]\n",
      " [0.0197981 ]\n",
      " [0.01957913]]\n",
      "185 [[0.01926519]\n",
      " [0.01940214]\n",
      " [0.01918755]]\n",
      "186 [[0.01887989]\n",
      " [0.0190141 ]\n",
      " [0.0188038 ]]\n",
      "187 [[0.01850229]\n",
      " [0.01863382]\n",
      " [0.01842772]]\n",
      "188 [[0.01813225]\n",
      " [0.01826114]\n",
      " [0.01805917]]\n",
      "189 [[0.0177696 ]\n",
      " [0.01789592]\n",
      " [0.01769799]]\n",
      "190 [[0.01741421]\n",
      " [0.017538  ]\n",
      " [0.01734403]]\n",
      "191 [[0.01706593]\n",
      " [0.01718724]\n",
      " [0.01699715]]\n",
      "192 [[0.01672461]\n",
      " [0.01684349]\n",
      " [0.0166572 ]]\n",
      "193 [[0.01639012]\n",
      " [0.01650662]\n",
      " [0.01632406]]\n",
      "194 [[0.01606231]\n",
      " [0.01617649]\n",
      " [0.01599758]]\n",
      "195 [[0.01574107]\n",
      " [0.01585296]\n",
      " [0.01567763]]\n",
      "196 [[0.01542625]\n",
      " [0.0155359 ]\n",
      " [0.01536407]]\n",
      "197 [[0.01511772]\n",
      " [0.01522518]\n",
      " [0.01505679]]\n",
      "198 [[0.01481537]\n",
      " [0.01492068]\n",
      " [0.01475566]]\n",
      "199 [[0.01451906]\n",
      " [0.01462227]\n",
      " [0.01446054]]\n",
      "200 [[0.01422868]\n",
      " [0.01432982]\n",
      " [0.01417133]]\n",
      "201 [[0.0139441 ]\n",
      " [0.01404322]\n",
      " [0.01388791]]\n",
      "202 [[0.01366522]\n",
      " [0.01376236]\n",
      " [0.01361015]]\n",
      "203 [[0.01339192]\n",
      " [0.01348711]\n",
      " [0.01333794]]\n",
      "204 [[0.01312408]\n",
      " [0.01321737]\n",
      " [0.01307119]]\n",
      "205 [[0.0128616 ]\n",
      " [0.01295302]\n",
      " [0.01280976]]\n",
      "206 [[0.01260437]\n",
      " [0.01269396]\n",
      " [0.01255357]]\n",
      "207 [[0.01235228]\n",
      " [0.01244008]\n",
      " [0.0123025 ]]\n",
      "208 [[0.01210523]\n",
      " [0.01219128]\n",
      " [0.01205645]]\n",
      "209 [[0.01186313]\n",
      " [0.01194746]\n",
      " [0.01181532]]\n",
      "210 [[0.01162587]\n",
      " [0.01170851]\n",
      " [0.01157901]]\n",
      "211 [[0.01139335]\n",
      " [0.01147434]\n",
      " [0.01134743]]\n",
      "212 [[0.01116548]\n",
      " [0.01124485]\n",
      " [0.01112048]]\n",
      "213 [[0.01094217]\n",
      " [0.01101995]\n",
      " [0.01089807]]\n",
      "214 [[0.01072333]\n",
      " [0.01079955]\n",
      " [0.01068011]]\n",
      "215 [[0.01050886]\n",
      " [0.01058356]\n",
      " [0.01046651]]\n",
      "216 [[0.01029868]\n",
      " [0.01037189]\n",
      " [0.01025718]]\n",
      "217 [[0.01009271]\n",
      " [0.01016445]\n",
      " [0.01005203]]\n",
      "218 [[0.00989086]\n",
      " [0.00996117]\n",
      " [0.00985099]]\n",
      "219 [[0.00969304]\n",
      " [0.00976194]\n",
      " [0.00965397]]\n",
      "220 [[0.00949918]\n",
      " [0.0095667 ]\n",
      " [0.00946089]]\n",
      "221 [[0.00930919]\n",
      " [0.00937537]\n",
      " [0.00927168]]\n",
      "222 [[0.00912301]\n",
      " [0.00918786]\n",
      " [0.00908624]]\n",
      "223 [[0.00894055]\n",
      " [0.0090041 ]\n",
      " [0.00890452]]\n",
      "224 [[0.00876174]\n",
      " [0.00882402]\n",
      " [0.00872643]]\n",
      "225 [[0.0085865 ]\n",
      " [0.00864754]\n",
      " [0.0085519 ]]\n",
      "226 [[0.00841477]\n",
      " [0.00847459]\n",
      " [0.00838086]]\n",
      "227 [[0.00824648]\n",
      " [0.0083051 ]\n",
      " [0.00821324]]\n",
      "228 [[0.00808155]\n",
      " [0.008139  ]\n",
      " [0.00804898]]\n",
      "229 [[0.00791992]\n",
      " [0.00797622]\n",
      " [0.007888  ]]\n",
      "230 [[0.00776152]\n",
      " [0.00781669]\n",
      " [0.00773024]]\n",
      "231 [[0.00760629]\n",
      " [0.00766036]\n",
      " [0.00757563]]\n",
      "232 [[0.00745416]\n",
      " [0.00750715]\n",
      " [0.00742412]]\n",
      "233 [[0.00730508]\n",
      " [0.00735701]\n",
      " [0.00727564]]\n",
      "234 [[0.00715898]\n",
      " [0.00720987]\n",
      " [0.00713013]]\n",
      "235 [[0.0070158 ]\n",
      " [0.00706567]\n",
      " [0.00698752]]\n",
      "236 [[0.00687548]\n",
      " [0.00692436]\n",
      " [0.00684777]]\n",
      "237 [[0.00673797]\n",
      " [0.00678587]\n",
      " [0.00671082]]\n",
      "238 [[0.00660321]\n",
      " [0.00665015]\n",
      " [0.0065766 ]]\n",
      "239 [[0.00647115]\n",
      " [0.00651715]\n",
      " [0.00644507]]\n",
      "240 [[0.00634173]\n",
      " [0.00638681]\n",
      " [0.00631617]]\n",
      "241 [[0.00621489]\n",
      " [0.00625907]\n",
      " [0.00618985]]\n",
      "242 [[0.00609059]\n",
      " [0.00613389]\n",
      " [0.00606605]]\n",
      "243 [[0.00596878]\n",
      " [0.00601121]\n",
      " [0.00594473]]\n",
      "244 [[0.00584941]\n",
      " [0.00589099]\n",
      " [0.00582583]]\n",
      "245 [[0.00573242]\n",
      " [0.00577317]\n",
      " [0.00570932]]\n",
      "246 [[0.00561777]\n",
      " [0.0056577 ]\n",
      " [0.00559513]]\n",
      "247 [[0.00550542]\n",
      " [0.00554455]\n",
      " [0.00548323]]\n",
      "248 [[0.00539531]\n",
      " [0.00543366]\n",
      " [0.00537356]]\n",
      "249 [[0.0052874 ]\n",
      " [0.00532499]\n",
      " [0.00526609]]\n",
      "250 [[0.00518165]\n",
      " [0.00521849]\n",
      " [0.00516077]]\n",
      "251 [[0.00507802]\n",
      " [0.00511412]\n",
      " [0.00505755]]\n",
      "252 [[0.00497646]\n",
      " [0.00501183]\n",
      " [0.0049564 ]]\n",
      "253 [[0.00487693]\n",
      " [0.0049116 ]\n",
      " [0.00485728]]\n",
      "254 [[0.00477939]\n",
      " [0.00481337]\n",
      " [0.00476013]]\n",
      "255 [[0.0046838 ]\n",
      " [0.0047171 ]\n",
      " [0.00466493]]\n",
      "256 [[0.00459013]\n",
      " [0.00462276]\n",
      " [0.00457163]]\n",
      "257 [[0.00449833]\n",
      " [0.0045303 ]\n",
      " [0.0044802 ]]\n",
      "258 [[0.00440836]\n",
      " [0.0044397 ]\n",
      " [0.00439059]]\n",
      "259 [[0.00432019]\n",
      " [0.0043509 ]\n",
      " [0.00430278]]\n",
      "260 [[0.00423379]\n",
      " [0.00426388]\n",
      " [0.00421672]]\n",
      "261 [[0.00414911]\n",
      " [0.00417861]\n",
      " [0.00413239]]\n",
      "262 [[0.00406613]\n",
      " [0.00409503]\n",
      " [0.00404974]]\n",
      "263 [[0.00398481]\n",
      " [0.00401313]\n",
      " [0.00396875]]\n",
      "264 [[0.00390511]\n",
      " [0.00393287]\n",
      " [0.00388937]]\n",
      "265 [[0.00382701]\n",
      " [0.00385421]\n",
      " [0.00381158]]\n",
      "266 [[0.00375047]\n",
      " [0.00377713]\n",
      " [0.00373535]]\n",
      "267 [[0.00367546]\n",
      " [0.00370159]\n",
      " [0.00366065]]\n",
      "268 [[0.00360195]\n",
      " [0.00362755]\n",
      " [0.00358743]]\n",
      "269 [[0.00352991]\n",
      " [0.003555  ]\n",
      " [0.00351568]]\n",
      "270 [[0.00345931]\n",
      " [0.0034839 ]\n",
      " [0.00344537]]\n",
      "271 [[0.00339013]\n",
      " [0.00341423]\n",
      " [0.00337646]]\n",
      "272 [[0.00332232]\n",
      " [0.00334594]\n",
      " [0.00330893]]\n",
      "273 [[0.00325588]\n",
      " [0.00327902]\n",
      " [0.00324276]]\n",
      "274 [[0.00319076]\n",
      " [0.00321344]\n",
      " [0.0031779 ]]\n",
      "275 [[0.00312694]\n",
      " [0.00314917]\n",
      " [0.00311434]]\n",
      "276 [[0.00306441]\n",
      " [0.00308619]\n",
      " [0.00305206]]\n",
      "277 [[0.00300312]\n",
      " [0.00302447]\n",
      " [0.00299101]]\n",
      "278 [[0.00294306]\n",
      " [0.00296398]\n",
      " [0.00293119]]\n",
      "279 [[0.00288419]\n",
      " [0.0029047 ]\n",
      " [0.00287257]]\n",
      "280 [[0.00282651]\n",
      " [0.0028466 ]\n",
      " [0.00281512]]\n",
      "281 [[0.00276998]\n",
      " [0.00278967]\n",
      " [0.00275882]]\n",
      "282 [[0.00271458]\n",
      " [0.00273388]\n",
      " [0.00270364]]\n",
      "283 [[0.00266029]\n",
      " [0.0026792 ]\n",
      " [0.00264957]]\n",
      "284 [[0.00260708]\n",
      " [0.00262562]\n",
      " [0.00259658]]\n",
      "285 [[0.00255494]\n",
      " [0.0025731 ]\n",
      " [0.00254464]]\n",
      "286 [[0.00250384]\n",
      " [0.00252164]\n",
      " [0.00249375]]\n",
      "287 [[0.00245377]\n",
      " [0.00247121]\n",
      " [0.00244388]]\n",
      "288 [[0.00240469]\n",
      " [0.00242178]\n",
      " [0.002395  ]]\n",
      "289 [[0.0023566 ]\n",
      " [0.00237335]\n",
      " [0.0023471 ]]\n",
      "290 [[0.00230946]\n",
      " [0.00232588]\n",
      " [0.00230016]]\n",
      "291 [[0.00226328]\n",
      " [0.00227936]\n",
      " [0.00225415]]\n",
      "292 [[0.00221801]\n",
      " [0.00223378]\n",
      " [0.00220907]]\n",
      "293 [[0.00217365]\n",
      " [0.0021891 ]\n",
      " [0.00216489]]\n",
      "294 [[0.00213018]\n",
      " [0.00214532]\n",
      " [0.00212159]]\n",
      "295 [[0.00208757]\n",
      " [0.00210241]\n",
      " [0.00207916]]\n",
      "296 [[0.00204582]\n",
      " [0.00206036]\n",
      " [0.00203758]]\n",
      "297 [[0.00200491]\n",
      " [0.00201916]\n",
      " [0.00199683]]\n",
      "298 [[0.00196481]\n",
      " [0.00197877]\n",
      " [0.00195689]]\n",
      "299 [[0.00192551]\n",
      " [0.0019392 ]\n",
      " [0.00191775]]\n",
      "300 [[0.001887  ]\n",
      " [0.00190041]\n",
      " [0.0018794 ]]\n",
      "301 [[0.00184926]\n",
      " [0.00186241]\n",
      " [0.00184181]]\n",
      "302 [[0.00181228]\n",
      " [0.00182516]\n",
      " [0.00180497]]\n",
      "303 [[0.00177603]\n",
      " [0.00178865]\n",
      " [0.00176887]]\n",
      "304 [[0.00174051]\n",
      " [0.00175288]\n",
      " [0.00173349]]\n",
      "305 [[0.0017057 ]\n",
      " [0.00171782]\n",
      " [0.00169882]]\n",
      "306 [[0.00167159]\n",
      " [0.00168347]\n",
      " [0.00166485]]\n",
      "307 [[0.00163815]\n",
      " [0.0016498 ]\n",
      " [0.00163155]]\n",
      "308 [[0.00160539]\n",
      " [0.0016168 ]\n",
      " [0.00159892]]\n",
      "309 [[0.00157328]\n",
      " [0.00158447]\n",
      " [0.00156694]]\n",
      "310 [[0.00154182]\n",
      " [0.00155278]\n",
      " [0.0015356 ]]\n",
      "311 [[0.00151098]\n",
      " [0.00152172]\n",
      " [0.00150489]]\n",
      "312 [[0.00148076]\n",
      " [0.00149129]\n",
      " [0.00147479]]\n",
      "313 [[0.00145115]\n",
      " [0.00146146]\n",
      " [0.0014453 ]]\n",
      "314 [[0.00142212]\n",
      " [0.00143223]\n",
      " [0.00141639]]\n",
      "315 [[0.00139368]\n",
      " [0.00140359]\n",
      " [0.00138806]]\n",
      "316 [[0.00136581]\n",
      " [0.00137552]\n",
      " [0.0013603 ]]\n",
      "317 [[0.00133849]\n",
      " [0.00134801]\n",
      " [0.0013331 ]]\n",
      "318 [[0.00131172]\n",
      " [0.00132105]\n",
      " [0.00130643]]\n",
      "319 [[0.00128549]\n",
      " [0.00129462]\n",
      " [0.00128031]]\n",
      "320 [[0.00125978]\n",
      " [0.00126873]\n",
      " [0.0012547 ]]\n",
      "321 [[0.00123458]\n",
      " [0.00124336]\n",
      " [0.00122961]]\n",
      "322 [[0.00120989]\n",
      " [0.00121849]\n",
      " [0.00120501]]\n",
      "323 [[0.00118569]\n",
      " [0.00119412]\n",
      " [0.00118091]]\n",
      "324 [[0.00116198]\n",
      " [0.00117024]\n",
      " [0.00115729]]\n",
      "325 [[0.00113874]\n",
      " [0.00114683]\n",
      " [0.00113415]]\n",
      "326 [[0.00111596]\n",
      " [0.0011239 ]\n",
      " [0.00111147]]\n",
      "327 [[0.00109364]\n",
      " [0.00110142]\n",
      " [0.00108924]]\n",
      "328 [[0.00107177]\n",
      " [0.00107939]\n",
      " [0.00106745]]\n",
      "329 [[0.00105034]\n",
      " [0.0010578 ]\n",
      " [0.0010461 ]]\n",
      "330 [[0.00102933]\n",
      " [0.00103665]\n",
      " [0.00102518]]\n",
      "331 [[0.00100874]\n",
      " [0.00101591]\n",
      " [0.00100468]]\n",
      "332 [[0.00098857]\n",
      " [0.0009956 ]\n",
      " [0.00098458]]\n",
      "333 [[0.0009688 ]\n",
      " [0.00097568]\n",
      " [0.00096489]]\n",
      "334 [[0.00094942]\n",
      " [0.00095617]\n",
      " [0.00094559]]\n",
      "335 [[0.00093043]\n",
      " [0.00093705]\n",
      " [0.00092668]]\n",
      "336 [[0.00091182]\n",
      " [0.00091831]\n",
      " [0.00090815]]\n",
      "337 [[0.00089359]\n",
      " [0.00089994]\n",
      " [0.00088999]]\n",
      "338 [[0.00087572]\n",
      " [0.00088194]\n",
      " [0.00087219]]\n",
      "339 [[0.0008582 ]\n",
      " [0.0008643 ]\n",
      " [0.00085474]]\n",
      "340 [[0.00084104]\n",
      " [0.00084702]\n",
      " [0.00083765]]\n",
      "341 [[0.00082422]\n",
      " [0.00083008]\n",
      " [0.00082089]]\n",
      "342 [[0.00080773]\n",
      " [0.00081347]\n",
      " [0.00080448]]\n",
      "343 [[0.00079158]\n",
      " [0.0007972 ]\n",
      " [0.00078839]]\n",
      "344 [[0.00077575]\n",
      " [0.00078126]\n",
      " [0.00077262]]\n",
      "345 [[0.00076023]\n",
      " [0.00076563]\n",
      " [0.00075717]]\n",
      "346 [[0.00074503]\n",
      " [0.00075032]\n",
      " [0.00074202]]\n",
      "347 [[0.00073013]\n",
      " [0.00073532]\n",
      " [0.00072718]]\n",
      "348 [[0.00071552]\n",
      " [0.00072061]\n",
      " [0.00071264]]\n",
      "349 [[0.00070121]\n",
      " [0.0007062 ]\n",
      " [0.00069839]]\n",
      "350 [[0.00068719]\n",
      " [0.00069207]\n",
      " [0.00068442]]\n",
      "351 [[0.00067344]\n",
      " [0.00067823]\n",
      " [0.00067073]]\n",
      "352 [[0.00065998]\n",
      " [0.00066467]\n",
      " [0.00065732]]\n",
      "353 [[0.00064678]\n",
      " [0.00065137]\n",
      " [0.00064417]]\n",
      "354 [[0.00063384]\n",
      " [0.00063835]\n",
      " [0.00063129]]\n",
      "355 [[0.00062116]\n",
      " [0.00062558]\n",
      " [0.00061866]]\n",
      "356 [[0.00060874]\n",
      " [0.00061307]\n",
      " [0.00060629]]\n",
      "357 [[0.00059657]\n",
      " [0.00060081]\n",
      " [0.00059416]]\n",
      "358 [[0.00058463]\n",
      " [0.00058879]\n",
      " [0.00058228]]\n",
      "359 [[0.00057294]\n",
      " [0.00057701]\n",
      " [0.00057063]]\n",
      "360 [[0.00056148]\n",
      " [0.00056547]\n",
      " [0.00055922]]\n",
      "361 [[0.00055025]\n",
      " [0.00055416]\n",
      " [0.00054804]]\n",
      "362 [[0.00053925]\n",
      " [0.00054308]\n",
      " [0.00053708]]\n",
      "363 [[0.00052846]\n",
      " [0.00053222]\n",
      " [0.00052633]]\n",
      "364 [[0.00051789]\n",
      " [0.00052158]\n",
      " [0.00051581]]\n",
      "365 [[0.00050754]\n",
      " [0.00051114]\n",
      " [0.00050549]]\n",
      "366 [[0.00049739]\n",
      " [0.00050092]\n",
      " [0.00049538]]\n",
      "367 [[0.00048744]\n",
      " [0.0004909 ]\n",
      " [0.00048547]]\n",
      "368 [[0.00047769]\n",
      " [0.00048108]\n",
      " [0.00047576]]\n",
      "369 [[0.00046814]\n",
      " [0.00047146]\n",
      " [0.00046625]]\n",
      "370 [[0.00045877]\n",
      " [0.00046203]\n",
      " [0.00045692]]\n",
      "371 [[0.0004496 ]\n",
      " [0.00045279]\n",
      " [0.00044779]]\n",
      "372 [[0.00044061]\n",
      " [0.00044374]\n",
      " [0.00043883]]\n",
      "373 [[0.00043179]\n",
      " [0.00043486]\n",
      " [0.00043005]]\n",
      "374 [[0.00042316]\n",
      " [0.00042617]\n",
      " [0.00042145]]\n",
      "375 [[0.00041469]\n",
      " [0.00041764]\n",
      " [0.00041302]]\n",
      "376 [[0.0004064 ]\n",
      " [0.00040929]\n",
      " [0.00040476]]\n",
      "377 [[0.00039827]\n",
      " [0.0004011 ]\n",
      " [0.00039667]]\n",
      "378 [[0.00039031]\n",
      " [0.00039308]\n",
      " [0.00038873]]\n",
      "379 [[0.0003825 ]\n",
      " [0.00038522]\n",
      " [0.00038096]]\n",
      "380 [[0.00037485]\n",
      " [0.00037752]\n",
      " [0.00037334]]\n",
      "381 [[0.00036735]\n",
      " [0.00036996]\n",
      " [0.00036587]]\n",
      "382 [[0.00036001]\n",
      " [0.00036257]\n",
      " [0.00035856]]\n",
      "383 [[0.00035281]\n",
      " [0.00035531]\n",
      " [0.00035138]]\n",
      "384 [[0.00034575]\n",
      " [0.00034821]\n",
      " [0.00034436]]\n",
      "385 [[0.00033884]\n",
      " [0.00034124]\n",
      " [0.00033747]]\n",
      "386 [[0.00033206]\n",
      " [0.00033442]\n",
      " [0.00033072]]\n",
      "387 [[0.00032542]\n",
      " [0.00032773]\n",
      " [0.00032411]]\n",
      "388 [[0.00031891]\n",
      " [0.00032118]\n",
      " [0.00031762]]\n",
      "389 [[0.00031253]\n",
      " [0.00031475]\n",
      " [0.00031127]]\n",
      "390 [[0.00030628]\n",
      " [0.00030846]\n",
      " [0.00030505]]\n",
      "391 [[0.00030015]\n",
      " [0.00030229]\n",
      " [0.00029894]]\n",
      "392 [[0.00029415]\n",
      " [0.00029624]\n",
      " [0.00029297]]\n",
      "393 [[0.00028827]\n",
      " [0.00029032]\n",
      " [0.00028711]]\n",
      "394 [[0.0002825 ]\n",
      " [0.00028451]\n",
      " [0.00028136]]\n",
      "395 [[0.00027685]\n",
      " [0.00027882]\n",
      " [0.00027574]]\n",
      "396 [[0.00027132]\n",
      " [0.00027324]\n",
      " [0.00027022]]\n",
      "397 [[0.00026589]\n",
      " [0.00026778]\n",
      " [0.00026482]]\n",
      "398 [[0.00026057]\n",
      " [0.00026242]\n",
      " [0.00025952]]\n",
      "399 [[0.00025536]\n",
      " [0.00025718]\n",
      " [0.00025433]]\n",
      "400 [[0.00025025]\n",
      " [0.00025203]\n",
      " [0.00024924]]\n",
      "401 [[0.00024525]\n",
      " [0.00024699]\n",
      " [0.00024426]]\n",
      "402 [[0.00024034]\n",
      " [0.00024205]\n",
      " [0.00023937]]\n",
      "403 [[0.00023554]\n",
      " [0.00023721]\n",
      " [0.00023459]]\n",
      "404 [[0.00023083]\n",
      " [0.00023247]\n",
      " [0.0002299 ]]\n",
      "405 [[0.00022621]\n",
      " [0.00022782]\n",
      " [0.0002253 ]]\n",
      "406 [[0.00022168]\n",
      " [0.00022326]\n",
      " [0.00022079]]\n",
      "407 [[0.00021725]\n",
      " [0.0002188 ]\n",
      " [0.00021638]]\n",
      "408 [[0.00021291]\n",
      " [0.00021442]\n",
      " [0.00021205]]\n",
      "409 [[0.00020865]\n",
      " [0.00021013]\n",
      " [0.00020781]]\n",
      "410 [[0.00020448]\n",
      " [0.00020593]\n",
      " [0.00020365]]\n",
      "411 [[0.00020039]\n",
      " [0.00020181]\n",
      " [0.00019958]]\n",
      "412 [[0.00019638]\n",
      " [0.00019777]\n",
      " [0.00019559]]\n",
      "413 [[0.00019245]\n",
      " [0.00019382]\n",
      " [0.00019167]]\n",
      "414 [[0.0001886 ]\n",
      " [0.00018994]\n",
      " [0.00018784]]\n",
      "415 [[0.00018483]\n",
      " [0.00018614]\n",
      " [0.00018408]]\n",
      "416 [[0.00018113]\n",
      " [0.00018242]\n",
      " [0.0001804 ]]\n",
      "417 [[0.00017751]\n",
      " [0.00017877]\n",
      " [0.00017679]]\n",
      "418 [[0.00017396]\n",
      " [0.0001752 ]\n",
      " [0.00017326]]\n",
      "419 [[0.00017048]\n",
      " [0.00017169]\n",
      " [0.00016979]]\n",
      "420 [[0.00016707]\n",
      " [0.00016826]\n",
      " [0.0001664 ]]\n",
      "421 [[0.00016373]\n",
      " [0.00016489]\n",
      " [0.00016307]]\n",
      "422 [[0.00016046]\n",
      " [0.0001616 ]\n",
      " [0.00015981]]\n",
      "423 [[0.00015725]\n",
      " [0.00015836]\n",
      " [0.00015661]]\n",
      "424 [[0.0001541 ]\n",
      " [0.0001552 ]\n",
      " [0.00015348]]\n",
      "425 [[0.00015102]\n",
      " [0.00015209]\n",
      " [0.00015041]]\n",
      "426 [[0.000148  ]\n",
      " [0.00014905]\n",
      " [0.0001474 ]]\n",
      "427 [[0.00014504]\n",
      " [0.00014607]\n",
      " [0.00014445]]\n",
      "428 [[0.00014214]\n",
      " [0.00014315]\n",
      " [0.00014157]]\n",
      "429 [[0.0001393 ]\n",
      " [0.00014029]\n",
      " [0.00013873]]\n",
      "430 [[0.00013651]\n",
      " [0.00013748]\n",
      " [0.00013596]]\n",
      "431 [[0.00013378]\n",
      " [0.00013473]\n",
      " [0.00013324]]\n",
      "432 [[0.0001311 ]\n",
      " [0.00013204]\n",
      " [0.00013058]]\n",
      "433 [[0.00012848]\n",
      " [0.00012939]\n",
      " [0.00012796]]\n",
      "434 [[0.00012591]\n",
      " [0.00012681]\n",
      " [0.0001254 ]]\n",
      "435 [[0.00012339]\n",
      " [0.00012427]\n",
      " [0.0001229 ]]\n",
      "436 [[0.00012093]\n",
      " [0.00012179]\n",
      " [0.00012044]]\n",
      "437 [[0.00011851]\n",
      " [0.00011935]\n",
      " [0.00011803]]\n",
      "438 [[0.00011614]\n",
      " [0.00011696]\n",
      " [0.00011567]]\n",
      "439 [[0.00011381]\n",
      " [0.00011462]\n",
      " [0.00011336]]\n",
      "440 [[0.00011154]\n",
      " [0.00011233]\n",
      " [0.00011109]]\n",
      "441 [[0.00010931]\n",
      " [0.00011008]\n",
      " [0.00010887]]\n",
      "442 [[0.00010712]\n",
      " [0.00010788]\n",
      " [0.00010669]]\n",
      "443 [[0.00010498]\n",
      " [0.00010572]\n",
      " [0.00010456]]\n",
      "444 [[0.00010288]\n",
      " [0.00010361]\n",
      " [0.00010246]]\n",
      "445 [[0.00010082]\n",
      " [0.00010154]\n",
      " [0.00010042]]\n",
      "446 [[9.88050522e-05]\n",
      " [9.95074043e-05]\n",
      " [9.84068449e-05]]\n",
      "447 [[9.68289511e-05]\n",
      " [9.75172562e-05]\n",
      " [9.64387080e-05]]\n",
      "448 [[9.48923721e-05]\n",
      " [9.55669111e-05]\n",
      " [9.45099339e-05]]\n",
      "449 [[9.29945247e-05]\n",
      " [9.36555729e-05]\n",
      " [9.26197352e-05]]\n",
      "450 [[9.11346342e-05]\n",
      " [9.17824614e-05]\n",
      " [9.07673405e-05]]\n",
      "451 [[8.93119415e-05]\n",
      " [8.99468122e-05]\n",
      " [8.89519937e-05]]\n",
      "452 [[8.75257027e-05]\n",
      " [8.81478760e-05]\n",
      " [8.71729538e-05]]\n",
      "453 [[8.57751886e-05]\n",
      " [8.63849184e-05]\n",
      " [8.54294947e-05]]\n",
      "454 [[8.40596848e-05]\n",
      " [8.46572201e-05]\n",
      " [8.37209048e-05]]\n",
      "455 [[8.23784912e-05]\n",
      " [8.29640757e-05]\n",
      " [8.20464868e-05]]\n",
      "456 [[8.07309213e-05]\n",
      " [8.13047942e-05]\n",
      " [8.04055570e-05]]\n",
      "457 [[7.91163029e-05]\n",
      " [7.96786983e-05]\n",
      " [7.87974459e-05]]\n",
      "458 [[7.75339768e-05]\n",
      " [7.80851243e-05]\n",
      " [7.72214970e-05]]\n",
      "459 [[7.59832973e-05]\n",
      " [7.65234218e-05]\n",
      " [7.56770670e-05]]\n",
      "460 [[7.44636314e-05]\n",
      " [7.49929534e-05]\n",
      " [7.41635257e-05]]\n",
      "461 [[7.29743587e-05]\n",
      " [7.34930943e-05]\n",
      " [7.26802552e-05]]\n",
      "462 [[7.15148716e-05]\n",
      " [7.20232324e-05]\n",
      " [7.12266501e-05]]\n",
      "463 [[7.00845741e-05]\n",
      " [7.05827678e-05]\n",
      " [6.98021171e-05]]\n",
      "464 [[6.86828826e-05]\n",
      " [6.91711124e-05]\n",
      " [6.84060747e-05]]\n",
      "465 [[6.73092250e-05]\n",
      " [6.77876902e-05]\n",
      " [6.70379532e-05]]\n",
      "466 [[6.59630405e-05]\n",
      " [6.64319364e-05]\n",
      " [6.56971942e-05]]\n",
      "467 [[6.46437797e-05]\n",
      " [6.51032977e-05]\n",
      " [6.43832503e-05]]\n",
      "468 [[6.33509041e-05]\n",
      " [6.38012317e-05]\n",
      " [6.30955853e-05]]\n",
      "469 [[6.20838860e-05]\n",
      " [6.25252071e-05]\n",
      " [6.18336736e-05]]\n",
      "470 [[6.08422083e-05]\n",
      " [6.12747029e-05]\n",
      " [6.05970001e-05]]\n",
      "471 [[5.96253641e-05]\n",
      " [6.00492089e-05]\n",
      " [5.93850601e-05]]\n",
      "472 [[5.84328568e-05]\n",
      " [5.88482247e-05]\n",
      " [5.81973589e-05]]\n",
      "473 [[5.72641997e-05]\n",
      " [5.76712602e-05]\n",
      " [5.70334117e-05]]\n",
      "474 [[5.61189157e-05]\n",
      " [5.65178350e-05]\n",
      " [5.58927435e-05]]\n",
      "475 [[5.49965374e-05]\n",
      " [5.53874783e-05]\n",
      " [5.47748886e-05]]\n",
      "476 [[5.38966066e-05]\n",
      " [5.42797287e-05]\n",
      " [5.36793908e-05]]\n",
      "477 [[5.28186745e-05]\n",
      " [5.31941341e-05]\n",
      " [5.26058030e-05]]\n",
      "478 [[5.17623010e-05]\n",
      " [5.21302515e-05]\n",
      " [5.15536870e-05]]\n",
      "479 [[5.07270550e-05]\n",
      " [5.10876464e-05]\n",
      " [5.05226132e-05]]\n",
      "480 [[4.97125139e-05]\n",
      " [5.00658935e-05]\n",
      " [4.95121610e-05]]\n",
      "481 [[4.87182636e-05]\n",
      " [4.90645756e-05]\n",
      " [4.85219177e-05]]\n",
      "482 [[4.77438984e-05]\n",
      " [4.80832841e-05]\n",
      " [4.75514794e-05]]\n",
      "483 [[4.67890204e-05]\n",
      " [4.71216184e-05]\n",
      " [4.66004498e-05]]\n",
      "484 [[4.58532400e-05]\n",
      " [4.61791861e-05]\n",
      " [4.56684408e-05]]\n",
      "485 [[4.49361752e-05]\n",
      " [4.52556024e-05]\n",
      " [4.47550720e-05]]\n",
      "486 [[4.40374517e-05]\n",
      " [4.43504903e-05]\n",
      " [4.38599705e-05]]\n",
      "487 [[4.31567026e-05]\n",
      " [4.34634805e-05]\n",
      " [4.29827711e-05]]\n",
      "488 [[4.22935686e-05]\n",
      " [4.25942109e-05]\n",
      " [4.21231157e-05]]\n",
      "489 [[4.14476972e-05]\n",
      " [4.17423267e-05]\n",
      " [4.12806534e-05]]\n",
      "490 [[4.06187433e-05]\n",
      " [4.09074801e-05]\n",
      " [4.04550403e-05]]\n",
      "491 [[3.98063684e-05]\n",
      " [4.00893305e-05]\n",
      " [3.96459395e-05]]\n",
      "492 [[3.90102410e-05]\n",
      " [3.92875439e-05]\n",
      " [3.88530207e-05]]\n",
      "493 [[3.82300362e-05]\n",
      " [3.85017930e-05]\n",
      " [3.80759603e-05]]\n",
      "494 [[3.74654355e-05]\n",
      " [3.77317572e-05]\n",
      " [3.73144411e-05]]\n",
      "495 [[3.67161268e-05]\n",
      " [3.69771220e-05]\n",
      " [3.65681523e-05]]\n",
      "496 [[3.59818042e-05]\n",
      " [3.62375796e-05]\n",
      " [3.58367892e-05]]\n",
      "497 [[3.52621682e-05]\n",
      " [3.55128280e-05]\n",
      " [3.51200535e-05]]\n",
      "498 [[3.45569248e-05]\n",
      " [3.48025714e-05]\n",
      " [3.44176524e-05]]\n",
      "499 [[3.38657863e-05]\n",
      " [3.41065200e-05]\n",
      " [3.37292993e-05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.37292993e-05])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    grad = sum_of_squares_gradient(v)\n",
    "    v = gradient_step(v, grad, -0.01)   \n",
    "    print(epoch, v)\n",
    "\n",
    "v[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
